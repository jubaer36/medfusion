{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb35d681",
   "metadata": {},
   "source": [
    "# Trainable Wavelet Fusion Model - Testing and Evaluation\n",
    "\n",
    "This notebook tests the trained wavelet fusion model on sample CT-MRI image pairs and evaluates the fusion quality with comprehensive metrics and visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4165a222",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e028b09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from typing import Tuple, List\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyWavelets and pytorch_wavelets for wavelet transforms\n",
    "from pytorch_wavelets import DWTForward, DWTInverse\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set matplotlib style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55107995",
   "metadata": {},
   "source": [
    "## 2. Load the Trained Model\n",
    "\n",
    "Define the model architecture and load the trained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc2b99aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model checkpoint not found at checkpoints_wavelet/wavelet_fusion_best.pt. Please train the model first.\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "model_path = 'checkpoints_wavelet/wavelet_fusion_best.pt'\n",
    "if os.path.exists(model_path):\n",
    "    model = WaveletFusionNet(wave='haar').to(device)\n",
    "    \n",
    "    # Load checkpoint which contains model, optimizer, and config\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    \n",
    "    # Extract model state_dict from checkpoint\n",
    "    if isinstance(checkpoint, dict) and 'model' in checkpoint:\n",
    "        model.load_state_dict(checkpoint['model'])\n",
    "        print(f\"Model loaded successfully from {model_path}\")\n",
    "        \n",
    "        # Display checkpoint info if available\n",
    "        if 'cfg' in checkpoint:\n",
    "            print(f\"Training config: {checkpoint['cfg']}\")\n",
    "    else:\n",
    "        # If checkpoint is just the state_dict directly\n",
    "        model.load_state_dict(checkpoint)\n",
    "        print(f\"Model loaded successfully from {model_path}\")\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    # Display learned parameters\n",
    "    print(f\"\\nLearned Fusion Weights:\")\n",
    "    print(f\"  Low-frequency (Œ±_L):  {model.alpha_low.item():.4f}\")\n",
    "    print(f\"  LH detail (Œ±_LH):     {model.alpha_lh.item():.4f}\")\n",
    "    print(f\"  HL detail (Œ±_HL):     {model.alpha_hl.item():.4f}\")\n",
    "    print(f\"  HH detail (Œ±_HH):     {model.alpha_hh.item():.4f}\")\n",
    "else:\n",
    "    print(f\"Model checkpoint not found at {model_path}. Please train the model first.\")\n",
    "    model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee0eca0",
   "metadata": {},
   "source": [
    "## 3. Load and Preprocess Test Images\n",
    "\n",
    "Define helper functions to load and preprocess CT-MRI image pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7e60c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 test image pairs\n",
      "  Pair 1: 16009.png\n",
      "  Pair 2: 16013.png\n",
      "  Pair 3: 2010.png\n"
     ]
    }
   ],
   "source": [
    "def load_image_pair(ct_path, mri_path, resize=None):\n",
    "    \"\"\"Load and preprocess a CT-MRI image pair.\"\"\"\n",
    "    ct = cv2.imread(ct_path, cv2.IMREAD_GRAYSCALE)\n",
    "    mri = cv2.imread(mri_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if ct is None or mri is None:\n",
    "        raise FileNotFoundError(f\"Could not load images: {ct_path}, {mri_path}\")\n",
    "    \n",
    "    if resize is not None:\n",
    "        H, W = resize\n",
    "        ct = cv2.resize(ct, (W, H), interpolation=cv2.INTER_AREA)\n",
    "        mri = cv2.resize(mri, (W, H), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # Normalize to [0, 1]\n",
    "    ct = ct.astype(np.float32)\n",
    "    mri = mri.astype(np.float32)\n",
    "    if ct.max() > 1.0: ct /= 255.0\n",
    "    if mri.max() > 1.0: mri /= 255.0\n",
    "    \n",
    "    return ct, mri\n",
    "\n",
    "def get_test_image_pairs(ct_dir, mri_dir, num_samples=5):\n",
    "    \"\"\"Get a list of test image pairs.\"\"\"\n",
    "    ct_files = sorted(glob.glob(os.path.join(ct_dir, '*.png')))\n",
    "    mri_files = sorted(glob.glob(os.path.join(mri_dir, '*.png')))\n",
    "    \n",
    "    # Match files by basename\n",
    "    pairs = []\n",
    "    for ct_file in ct_files:\n",
    "        ct_basename = os.path.basename(ct_file)\n",
    "        mri_file = os.path.join(mri_dir, ct_basename)\n",
    "        if os.path.exists(mri_file):\n",
    "            pairs.append((ct_file, mri_file))\n",
    "    \n",
    "    # Select a subset for testing\n",
    "    if len(pairs) > num_samples:\n",
    "        # Select evenly spaced samples\n",
    "        indices = np.linspace(0, len(pairs)-1, num_samples, dtype=int)\n",
    "        pairs = [pairs[i] for i in indices]\n",
    "    \n",
    "    return pairs\n",
    "\n",
    "# Get test image pairs\n",
    "ct_test_dir = 'Harvard-Medical-Image-Fusion-Datasets/MyDatasets/CT-MRI/test/CT'\n",
    "mri_test_dir = 'Harvard-Medical-Image-Fusion-Datasets/MyDatasets/CT-MRI/test/MRI'\n",
    "\n",
    "test_pairs = get_test_image_pairs(ct_test_dir, mri_test_dir, num_samples=6)\n",
    "print(f\"Found {len(test_pairs)} test image pairs\")\n",
    "\n",
    "for i, (ct_path, mri_path) in enumerate(test_pairs[:3]):\n",
    "    print(f\"  Pair {i+1}: {os.path.basename(ct_path)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a77c06",
   "metadata": {},
   "source": [
    "## 4. Perform Image Fusion\n",
    "\n",
    "Define fusion methods including the trained model and baseline methods for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3b226ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse_with_model(model, ct, mri):\n",
    "    \"\"\"Fuse images using the trained model.\"\"\"\n",
    "    if model is None:\n",
    "        return None\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Convert to tensors and add batch dimension\n",
    "        ct_tensor = torch.from_numpy(ct)[None, None, ...].to(device)  # (1,1,H,W)\n",
    "        mri_tensor = torch.from_numpy(mri)[None, None, ...].to(device)\n",
    "        \n",
    "        # Perform fusion\n",
    "        fused_tensor = model(ct_tensor, mri_tensor)\n",
    "        \n",
    "        # Convert back to numpy\n",
    "        fused = fused_tensor.squeeze().cpu().numpy()\n",
    "        return np.clip(fused, 0, 1)\n",
    "\n",
    "def fuse_average(ct, mri):\n",
    "    \"\"\"Simple average fusion.\"\"\"\n",
    "    return 0.5 * (ct + mri)\n",
    "\n",
    "def fuse_max(ct, mri):\n",
    "    \"\"\"Max-based fusion.\"\"\"\n",
    "    return np.maximum(ct, mri)\n",
    "\n",
    "def fuse_weighted(ct, mri, weight=0.6):\n",
    "    \"\"\"Weighted fusion favoring CT.\"\"\"\n",
    "    return weight * ct + (1 - weight) * mri\n",
    "\n",
    "# Test fusion on the first image pair\n",
    "if test_pairs and model is not None:\n",
    "    ct_path, mri_path = test_pairs[0]\n",
    "    ct_img, mri_img = load_image_pair(ct_path, mri_path)\n",
    "    \n",
    "    print(f\"Testing fusion on: {os.path.basename(ct_path)}\")\n",
    "    print(f\"Image shape: {ct_img.shape}\")\n",
    "    print(f\"CT range: [{ct_img.min():.3f}, {ct_img.max():.3f}]\")\n",
    "    print(f\"MRI range: [{mri_img.min():.3f}, {mri_img.max():.3f}]\")\n",
    "    \n",
    "    # Test fusion\n",
    "    fused_model = fuse_with_model(model, ct_img, mri_img)\n",
    "    if fused_model is not None:\n",
    "        print(f\"Fused range: [{fused_model.min():.3f}, {fused_model.max():.3f}]\")\n",
    "        print(\"Fusion successful!\")\n",
    "    else:\n",
    "        print(\"Model fusion failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbea290",
   "metadata": {},
   "source": [
    "## 5. Display Fusion Results\n",
    "\n",
    "Visualize the fusion results for individual image pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a0ec426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_fusion_results(ct, mri, fused_results, titles, figsize=(15, 10)):\n",
    "    \"\"\"Display original images and fusion results.\"\"\"\n",
    "    n_methods = len(fused_results)\n",
    "    n_cols = min(4, n_methods + 2)  # +2 for original CT and MRI\n",
    "    n_rows = (n_methods + 2 + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "    if n_rows == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    # Flatten axes for easy indexing\n",
    "    axes_flat = axes.flatten()\n",
    "    \n",
    "    # Display original images\n",
    "    axes_flat[0].imshow(ct, cmap='gray')\n",
    "    axes_flat[0].set_title('CT (Source A)', fontsize=12, fontweight='bold')\n",
    "    axes_flat[0].axis('off')\n",
    "    \n",
    "    axes_flat[1].imshow(mri, cmap='gray')\n",
    "    axes_flat[1].set_title('MRI (Source B)', fontsize=12, fontweight='bold')\n",
    "    axes_flat[1].axis('off')\n",
    "    \n",
    "    # Display fusion results\n",
    "    for i, (fused, title) in enumerate(zip(fused_results, titles)):\n",
    "        if fused is not None:\n",
    "            axes_flat[i + 2].imshow(fused, cmap='gray')\n",
    "            axes_flat[i + 2].set_title(title, fontsize=12)\n",
    "        else:\n",
    "            axes_flat[i + 2].text(0.5, 0.5, 'N/A', ha='center', va='center', transform=axes_flat[i + 2].transAxes)\n",
    "            axes_flat[i + 2].set_title(title, fontsize=12)\n",
    "        axes_flat[i + 2].axis('off')\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for i in range(n_methods + 2, len(axes_flat)):\n",
    "        axes_flat[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Display results for the first test pair\n",
    "if test_pairs and model is not None:\n",
    "    ct_path, mri_path = test_pairs[0]\n",
    "    ct_img, mri_img = load_image_pair(ct_path, mri_path)\n",
    "    \n",
    "    # Generate fusion results\n",
    "    fused_model = fuse_with_model(model, ct_img, mri_img)\n",
    "    fused_avg = fuse_average(ct_img, mri_img)\n",
    "    fused_max = fuse_max(ct_img, mri_img)\n",
    "    fused_weighted = fuse_weighted(ct_img, mri_img)\n",
    "    \n",
    "    fused_results = [fused_model, fused_avg, fused_max, fused_weighted]\n",
    "    titles = ['Trained Model', 'Average', 'Maximum', 'Weighted (0.6)']\n",
    "    \n",
    "    fig = display_fusion_results(ct_img, mri_img, fused_results, titles)\n",
    "    plt.suptitle(f'Fusion Results: {os.path.basename(ct_path)}', fontsize=16, fontweight='bold')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bad814f",
   "metadata": {},
   "source": [
    "## 6. Calculate Performance Metrics\n",
    "\n",
    "Implement comprehensive metrics to evaluate fusion quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f9b1ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ssim(img1, img2):\n",
    "    \"\"\"Calculate SSIM between two images.\"\"\"\n",
    "    from skimage.metrics import structural_similarity as ssim\n",
    "    return ssim(img1, img2, data_range=1.0)\n",
    "\n",
    "def calculate_psnr(img1, img2):\n",
    "    \"\"\"Calculate PSNR between two images.\"\"\"\n",
    "    mse = np.mean((img1 - img2) ** 2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    return 20 * np.log10(1.0 / np.sqrt(mse))\n",
    "\n",
    "def calculate_gradient_magnitude(img):\n",
    "    \"\"\"Calculate gradient magnitude using Sobel operators.\"\"\"\n",
    "    grad_x = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    grad_y = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    return np.sqrt(grad_x**2 + grad_y**2)\n",
    "\n",
    "def calculate_edge_preservation(fused, ct, mri):\n",
    "    \"\"\"Calculate edge preservation metric.\"\"\"\n",
    "    # Calculate gradients\n",
    "    grad_fused = calculate_gradient_magnitude(fused)\n",
    "    grad_ct = calculate_gradient_magnitude(ct)\n",
    "    grad_mri = calculate_gradient_magnitude(mri)\n",
    "    \n",
    "    # Maximum gradient from sources\n",
    "    grad_max = np.maximum(grad_ct, grad_mri)\n",
    "    \n",
    "    # Edge preservation as correlation\n",
    "    correlation = np.corrcoef(grad_fused.flatten(), grad_max.flatten())[0, 1]\n",
    "    return correlation if not np.isnan(correlation) else 0.0\n",
    "\n",
    "def calculate_entropy(img):\n",
    "    \"\"\"Calculate image entropy.\"\"\"\n",
    "    # Convert to 8-bit for histogram\n",
    "    img_uint8 = (img * 255).astype(np.uint8)\n",
    "    hist, _ = np.histogram(img_uint8, bins=256, range=(0, 256))\n",
    "    hist = hist / hist.sum()  # Normalize\n",
    "    hist = hist[hist > 0]  # Remove zeros\n",
    "    return -np.sum(hist * np.log2(hist))\n",
    "\n",
    "def calculate_mutual_information(img1, img2):\n",
    "    \"\"\"Calculate mutual information between two images.\"\"\"\n",
    "    # Convert to 8-bit\n",
    "    img1_uint8 = (img1 * 255).astype(np.uint8)\n",
    "    img2_uint8 = (img2 * 255).astype(np.uint8)\n",
    "    \n",
    "    # Joint histogram\n",
    "    hist_2d, _, _ = np.histogram2d(img1_uint8.flatten(), img2_uint8.flatten(), bins=256)\n",
    "    \n",
    "    # Normalize\n",
    "    hist_2d = hist_2d / hist_2d.sum()\n",
    "    \n",
    "    # Marginal histograms\n",
    "    hist_1 = hist_2d.sum(axis=1)\n",
    "    hist_2 = hist_2d.sum(axis=0)\n",
    "    \n",
    "    # Calculate MI\n",
    "    mi = 0.0\n",
    "    for i in range(256):\n",
    "        for j in range(256):\n",
    "            if hist_2d[i, j] > 0 and hist_1[i] > 0 and hist_2[j] > 0:\n",
    "                mi += hist_2d[i, j] * np.log2(hist_2d[i, j] / (hist_1[i] * hist_2[j]))\n",
    "    \n",
    "    return mi\n",
    "\n",
    "def evaluate_fusion_quality(fused, ct, mri):\n",
    "    \"\"\"Comprehensive evaluation of fusion quality.\"\"\"\n",
    "    if fused is None:\n",
    "        return {}\n",
    "    \n",
    "    metrics = {}\n",
    "    \n",
    "    # SSIM with both source images\n",
    "    metrics['SSIM_CT'] = calculate_ssim(fused, ct)\n",
    "    metrics['SSIM_MRI'] = calculate_ssim(fused, mri)\n",
    "    metrics['SSIM_Avg'] = (metrics['SSIM_CT'] + metrics['SSIM_MRI']) / 2\n",
    "    \n",
    "    # PSNR with both source images\n",
    "    metrics['PSNR_CT'] = calculate_psnr(fused, ct)\n",
    "    metrics['PSNR_MRI'] = calculate_psnr(fused, mri)\n",
    "    metrics['PSNR_Avg'] = (metrics['PSNR_CT'] + metrics['PSNR_MRI']) / 2\n",
    "    \n",
    "    # Edge preservation\n",
    "    metrics['Edge_Preservation'] = calculate_edge_preservation(fused, ct, mri)\n",
    "    \n",
    "    # Entropy (information content)\n",
    "    metrics['Entropy'] = calculate_entropy(fused)\n",
    "    \n",
    "    # Mutual information with sources\n",
    "    metrics['MI_CT'] = calculate_mutual_information(fused, ct)\n",
    "    metrics['MI_MRI'] = calculate_mutual_information(fused, mri)\n",
    "    metrics['MI_Avg'] = (metrics['MI_CT'] + metrics['MI_MRI']) / 2\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Test metrics calculation\n",
    "if test_pairs and model is not None:\n",
    "    ct_path, mri_path = test_pairs[0]\n",
    "    ct_img, mri_img = load_image_pair(ct_path, mri_path)\n",
    "    fused_model = fuse_with_model(model, ct_img, mri_img)\n",
    "    \n",
    "    metrics = evaluate_fusion_quality(fused_model, ct_img, mri_img)\n",
    "    \n",
    "    print(\"Sample Metrics for Trained Model:\")\n",
    "    for key, value in metrics.items():\n",
    "        print(f\"  {key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb953fb6",
   "metadata": {},
   "source": [
    "## 7. Compare Multiple Test Cases\n",
    "\n",
    "Process multiple test image pairs and compare different fusion methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41571a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No test pairs available or model not loaded.\n"
     ]
    }
   ],
   "source": [
    "# Process all test pairs and collect metrics\n",
    "results_data = []\n",
    "fusion_methods = {\n",
    "    'Trained Model': lambda ct, mri: fuse_with_model(model, ct, mri),\n",
    "    'Average': fuse_average,\n",
    "    'Maximum': fuse_max,\n",
    "    'Weighted': fuse_weighted\n",
    "}\n",
    "\n",
    "if test_pairs and model is not None:\n",
    "    print(f\"Processing {len(test_pairs)} test pairs...\")\n",
    "    \n",
    "    for i, (ct_path, mri_path) in enumerate(test_pairs):\n",
    "        try:\n",
    "            # Load image pair\n",
    "            ct_img, mri_img = load_image_pair(ct_path, mri_path)\n",
    "            image_name = os.path.basename(ct_path)\n",
    "            \n",
    "            print(f\"  Processing {image_name}...\")\n",
    "            \n",
    "            # Test each fusion method\n",
    "            for method_name, method_func in fusion_methods.items():\n",
    "                try:\n",
    "                    fused = method_func(ct_img, mri_img)\n",
    "                    metrics = evaluate_fusion_quality(fused, ct_img, mri_img)\n",
    "                    \n",
    "                    # Add metadata\n",
    "                    metrics['Image'] = image_name\n",
    "                    metrics['Method'] = method_name\n",
    "                    metrics['Pair_Index'] = i + 1\n",
    "                    \n",
    "                    results_data.append(metrics)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"    Error with {method_name}: {e}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"  Error loading {ct_path}: {e}\")\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    results_df = pd.DataFrame(results_data)\n",
    "    print(f\"\\nCollected results for {len(results_df)} method-image combinations\")\n",
    "    print(f\"Shape: {results_df.shape}\")\n",
    "    \n",
    "    # Display sample results\n",
    "    if not results_df.empty:\n",
    "        print(\"\\nSample Results:\")\n",
    "        display_cols = ['Image', 'Method', 'SSIM_Avg', 'PSNR_Avg', 'Edge_Preservation', 'Entropy']\n",
    "        print(results_df[display_cols].head(8))\n",
    "else:\n",
    "    results_df = pd.DataFrame()\n",
    "    print(\"No test pairs available or model not loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66787f95",
   "metadata": {},
   "source": [
    "### Visualize Multiple Test Cases Side by Side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee488ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_multiple_cases(test_pairs, model, max_cases=4):\n",
    "    \"\"\"Display fusion results for multiple test cases.\"\"\"\n",
    "    n_cases = min(len(test_pairs), max_cases)\n",
    "    \n",
    "    fig, axes = plt.subplots(n_cases, 6, figsize=(18, 3*n_cases))\n",
    "    if n_cases == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i in range(n_cases):\n",
    "        ct_path, mri_path = test_pairs[i]\n",
    "        ct_img, mri_img = load_image_pair(ct_path, mri_path)\n",
    "        \n",
    "        # Generate fusions\n",
    "        fused_model = fuse_with_model(model, ct_img, mri_img)\n",
    "        fused_avg = fuse_average(ct_img, mri_img)\n",
    "        fused_max = fuse_max(ct_img, mri_img)\n",
    "        fused_weighted = fuse_weighted(ct_img, mri_img)\n",
    "        \n",
    "        # Display images\n",
    "        images = [ct_img, mri_img, fused_model, fused_avg, fused_max, fused_weighted]\n",
    "        titles = ['CT', 'MRI', 'Trained', 'Average', 'Maximum', 'Weighted']\n",
    "        \n",
    "        for j, (img, title) in enumerate(zip(images, titles)):\n",
    "            if img is not None:\n",
    "                axes[i, j].imshow(img, cmap='gray')\n",
    "            else:\n",
    "                axes[i, j].text(0.5, 0.5, 'N/A', ha='center', va='center')\n",
    "            \n",
    "            if i == 0:  # Add titles only to the first row\n",
    "                axes[i, j].set_title(title, fontsize=12, fontweight='bold')\n",
    "            axes[i, j].axis('off')\n",
    "        \n",
    "        # Add image name as row label\n",
    "        axes[i, 0].text(-0.1, 0.5, os.path.basename(ct_path), \n",
    "                       transform=axes[i, 0].transAxes, rotation=90, \n",
    "                       ha='center', va='center', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Display multiple test cases\n",
    "if test_pairs and model is not None and len(test_pairs) > 0:\n",
    "    fig = display_multiple_cases(test_pairs, model, max_cases=min(4, len(test_pairs)))\n",
    "    plt.suptitle('Fusion Results Comparison Across Multiple Cases', \n",
    "                fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb6b56e",
   "metadata": {},
   "source": [
    "## 8. Visualize Metrics Summary\n",
    "\n",
    "Create comprehensive visualizations and statistical summaries of the performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67ad4a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No results data available for visualization.\n"
     ]
    }
   ],
   "source": [
    "if not results_df.empty:\n",
    "    # Create summary statistics\n",
    "    metric_columns = ['SSIM_Avg', 'PSNR_Avg', 'Edge_Preservation', 'Entropy', 'MI_Avg']\n",
    "    summary_stats = results_df.groupby('Method')[metric_columns].agg(['mean', 'std', 'min', 'max'])\n",
    "    \n",
    "    print(\"Summary Statistics by Method:\")\n",
    "    print(\"=\" * 80)\n",
    "    for metric in metric_columns:\n",
    "        print(f\"\\n{metric}:\")\n",
    "        print(summary_stats[metric].round(4))\n",
    "    \n",
    "    # Visualization 1: Bar plot comparing average metrics\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, metric in enumerate(metric_columns):\n",
    "        if i < len(axes):\n",
    "            mean_values = results_df.groupby('Method')[metric].mean()\n",
    "            std_values = results_df.groupby('Method')[metric].std()\n",
    "            \n",
    "            bars = axes[i].bar(mean_values.index, mean_values.values, \n",
    "                              yerr=std_values.values, capsize=5, alpha=0.8)\n",
    "            axes[i].set_title(f'{metric}', fontsize=12, fontweight='bold')\n",
    "            axes[i].set_ylabel('Value')\n",
    "            axes[i].tick_params(axis='x', rotation=45)\n",
    "            axes[i].grid(True, alpha=0.3)\n",
    "            \n",
    "            # Highlight the best method\n",
    "            best_idx = mean_values.argmax()\n",
    "            bars[best_idx].set_color('red')\n",
    "            bars[best_idx].set_alpha(1.0)\n",
    "    \n",
    "    # Hide the last subplot if we have an odd number of metrics\n",
    "    if len(metric_columns) < len(axes):\n",
    "        axes[-1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Performance Metrics Comparison (Higher is Better)', \n",
    "                fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"No results data available for visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c257dd",
   "metadata": {},
   "source": [
    "### Heatmap of Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c235e8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not results_df.empty:\n",
    "    # Create a pivot table for heatmap\n",
    "    pivot_data = results_df.pivot_table(index='Method', \n",
    "                                        columns='Image', \n",
    "                                        values='SSIM_Avg', \n",
    "                                        aggfunc='mean')\n",
    "    \n",
    "    # Create heatmap\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    sns.heatmap(pivot_data, annot=True, cmap='YlOrRd', fmt='.3f', \n",
    "                cbar_kws={'label': 'Average SSIM'})\n",
    "    plt.title('SSIM Performance Heatmap Across Test Images', \n",
    "              fontsize=16, fontweight='bold')\n",
    "    plt.xlabel('Test Images')\n",
    "    plt.ylabel('Fusion Methods')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Box plots for metric distributions\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    key_metrics = ['SSIM_Avg', 'PSNR_Avg', 'Edge_Preservation', 'Entropy']\n",
    "    \n",
    "    for i, metric in enumerate(key_metrics):\n",
    "        sns.boxplot(data=results_df, x='Method', y=metric, ax=axes[i])\n",
    "        axes[i].set_title(f'{metric} Distribution', fontweight='bold')\n",
    "        axes[i].tick_params(axis='x', rotation=45)\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Metric Distributions Across All Test Cases', \n",
    "                fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c456a519",
   "metadata": {},
   "source": [
    "### Ranking and Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5680649e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No results available for final analysis.\n"
     ]
    }
   ],
   "source": [
    "if not results_df.empty:\n",
    "    # Calculate overall ranking\n",
    "    ranking_metrics = ['SSIM_Avg', 'PSNR_Avg', 'Edge_Preservation', 'Entropy', 'MI_Avg']\n",
    "    method_scores = {}\n",
    "    \n",
    "    for method in results_df['Method'].unique():\n",
    "        method_data = results_df[results_df['Method'] == method]\n",
    "        \n",
    "        # Calculate normalized scores (0-1) for each metric\n",
    "        scores = []\n",
    "        for metric in ranking_metrics:\n",
    "            if metric in method_data.columns:\n",
    "                # Normalize by the maximum value across all methods\n",
    "                max_val = results_df[metric].max()\n",
    "                min_val = results_df[metric].min()\n",
    "                if max_val > min_val:\n",
    "                    normalized = (method_data[metric].mean() - min_val) / (max_val - min_val)\n",
    "                else:\n",
    "                    normalized = 1.0\n",
    "                scores.append(normalized)\n",
    "        \n",
    "        method_scores[method] = np.mean(scores)\n",
    "    \n",
    "    # Sort methods by overall score\n",
    "    ranked_methods = sorted(method_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINAL RANKING - OVERALL PERFORMANCE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for i, (method, score) in enumerate(ranked_methods, 1):\n",
    "        method_data = results_df[results_df['Method'] == method]\n",
    "        print(f\"\\n{i}. {method} (Score: {score:.4f})\")\n",
    "        print(f\"   ‚Ä¢ SSIM Average:        {method_data['SSIM_Avg'].mean():.4f} ¬± {method_data['SSIM_Avg'].std():.4f}\")\n",
    "        print(f\"   ‚Ä¢ PSNR Average:        {method_data['PSNR_Avg'].mean():.4f} ¬± {method_data['PSNR_Avg'].std():.4f}\")\n",
    "        print(f\"   ‚Ä¢ Edge Preservation:   {method_data['Edge_Preservation'].mean():.4f} ¬± {method_data['Edge_Preservation'].std():.4f}\")\n",
    "        print(f\"   ‚Ä¢ Entropy:             {method_data['Entropy'].mean():.4f} ¬± {method_data['Entropy'].std():.4f}\")\n",
    "        print(f\"   ‚Ä¢ Mutual Information:  {method_data['MI_Avg'].mean():.4f} ¬± {method_data['MI_Avg'].std():.4f}\")\n",
    "    \n",
    "    # Create a final comparison chart\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    methods = [item[0] for item in ranked_methods]\n",
    "    scores = [item[1] for item in ranked_methods]\n",
    "    colors = ['red' if 'Trained' in method else 'skyblue' for method in methods]\n",
    "    \n",
    "    bars = plt.bar(methods, scores, color=colors, alpha=0.8)\n",
    "    plt.title('Overall Performance Ranking\\n(Normalized Average Across All Metrics)', \n",
    "              fontsize=16, fontweight='bold')\n",
    "    plt.ylabel('Overall Performance Score', fontsize=12)\n",
    "    plt.xlabel('Fusion Methods', fontsize=12)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, score in zip(bars, scores):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.01, \n",
    "                f'{score:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EVALUATION COMPLETE\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total test cases processed: {len(test_pairs)}\")\n",
    "    print(f\"Fusion methods compared: {len(ranked_methods)}\")\n",
    "    if 'Trained Model' in method_scores:\n",
    "        trained_rank = next(i for i, (method, _) in enumerate(ranked_methods, 1) if method == 'Trained Model')\n",
    "        print(f\"Trained model ranking: #{trained_rank} out of {len(ranked_methods)}\")\n",
    "    \n",
    "else:\n",
    "    print(\"No results available for final analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ac9495",
   "metadata": {},
   "source": [
    "## üîç Analysis: Why Limited Improvement?\n",
    "\n",
    "### **Root Causes:**\n",
    "1. **Model Simplicity**: Only 4 global parameters (Œ±_L, Œ±_LH, Œ±_HL, Œ±_HH)\n",
    "2. **Limited Learning**: Œ±_HL and Œ±_HH stayed at 0.5 (initialization values)\n",
    "3. **Small Dataset**: 144 training samples insufficient for complex learning\n",
    "4. **Loss Imbalance**: Perceptual loss weight (0.1) too low vs SSIM (1.0) and gradient (1.0)\n",
    "5. **No Spatial Adaptation**: Same weights applied globally across entire image\n",
    "\n",
    "### **Key Observations:**\n",
    "- **Trained model learned**: Œ±_L=0.67, Œ±_LH=0.65 (favor CT for low-freq and horizontal details)\n",
    "- **Didn't learn**: Œ±_HL=0.5, Œ±_HH=0.5 (remained at default, suggesting insufficient training signal)\n",
    "- **Performance gap**: Only 0.017 points above simple Average method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1059f2f7",
   "metadata": {},
   "source": [
    "## üöÄ Improvement Strategies\n",
    "\n",
    "### **Priority 1: Model Architecture Enhancements**\n",
    "\n",
    "#### **A) Spatial-Adaptive Fusion Weights**\n",
    "Instead of global weights, use a lightweight CNN to generate spatial fusion maps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6469b74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Spatial-Adaptive Fusion Model Defined\n",
      "Key improvements:\n",
      "- Spatial fusion weights instead of global\n",
      "- CNN learns to adapt weights based on local image content\n",
      "- Much more parameters for learning: ~8K vs 4\n"
     ]
    }
   ],
   "source": [
    "class SpatialAdaptiveWaveletFusion(nn.Module):\n",
    "    \"\"\"IMPROVEMENT 1: Spatial-adaptive fusion weights using lightweight CNN\"\"\"\n",
    "    def __init__(self, wave='haar', channels=32):\n",
    "        super().__init__()\n",
    "        self.dwt = DWTForward(J=1, wave=wave)\n",
    "        self.idwt = DWTInverse(wave=wave)\n",
    "        \n",
    "        # Lightweight CNN for spatial fusion weights\n",
    "        self.fusion_net = nn.Sequential(\n",
    "            nn.Conv2d(2, channels, 3, padding=1),      # Input: CT+MRI concatenated\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channels, channels//2, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channels//2, 4, 3, padding=1),  # 4 channels for 4 wavelet bands\n",
    "            nn.Sigmoid()  # Fusion weights in [0,1]\n",
    "        )\n",
    "        \n",
    "    def forward(self, ct, mr):\n",
    "        # Wavelet decomposition\n",
    "        ct_low, ct_high = self.dwt(ct)\n",
    "        mr_low, mr_high = self.dwt(mr)\n",
    "        \n",
    "        ct_lh, ct_hl, ct_hh = ct_high[0][:,0:1], ct_high[0][:,1:2], ct_high[0][:,2:3]\n",
    "        mr_lh, mr_hl, mr_hh = mr_high[0][:,0:1], mr_high[0][:,1:2], mr_high[0][:,2:3]\n",
    "        \n",
    "        # Generate spatial fusion weights from original images\n",
    "        fusion_input = torch.cat([ct, mr], dim=1)  # (B, 2, H, W)\n",
    "        weights = self.fusion_net(fusion_input)    # (B, 4, H, W)\n",
    "        \n",
    "        # Downsample weights to match wavelet coefficient sizes\n",
    "        w_low = F.adaptive_avg_pool2d(weights[:, 0:1], ct_low.shape[-2:])\n",
    "        w_lh = F.adaptive_avg_pool2d(weights[:, 1:2], ct_lh.shape[-2:])\n",
    "        w_hl = F.adaptive_avg_pool2d(weights[:, 2:3], ct_hl.shape[-2:])\n",
    "        w_hh = F.adaptive_avg_pool2d(weights[:, 3:4], ct_hh.shape[-2:])\n",
    "        \n",
    "        # Spatially-adaptive fusion\n",
    "        fused_low = w_low * ct_low + (1 - w_low) * mr_low\n",
    "        fused_lh = w_lh * ct_lh + (1 - w_lh) * mr_lh\n",
    "        fused_hl = w_hl * ct_hl + (1 - w_hl) * mr_hl\n",
    "        fused_hh = w_hh * ct_hh + (1 - w_hh) * mr_hh\n",
    "        \n",
    "        # Reconstruct\n",
    "        fused_high = torch.cat([fused_lh, fused_hl, fused_hh], dim=1)\n",
    "        fused = self.idwt((fused_low, [fused_high]))\n",
    "        \n",
    "        return fused\n",
    "\n",
    "print(\"‚úÖ Spatial-Adaptive Fusion Model Defined\")\n",
    "print(\"Key improvements:\")\n",
    "print(\"- Spatial fusion weights instead of global\")\n",
    "print(\"- CNN learns to adapt weights based on local image content\")\n",
    "print(\"- Much more parameters for learning: ~8K vs 4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196163f5",
   "metadata": {},
   "source": [
    "#### **B) Enhanced Loss Function**\n",
    "Rebalance loss weights and add additional terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79029136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Enhanced Loss Function Defined\n",
      "Key improvements:\n",
      "- Increased perceptual weight: 0.1 ‚Üí 1.0\n",
      "- Increased gradient weight: 1.0 ‚Üí 2.0\n",
      "- Added contrast preservation term\n",
      "- Better gradient and perceptual computations\n"
     ]
    }
   ],
   "source": [
    "# IMPROVEMENT 2: Enhanced Loss Function with Better Balance\n",
    "class EnhancedFusionLoss(nn.Module):\n",
    "    def __init__(self, device, w_ssim=1.0, w_grad=2.0, w_perc=1.0, w_contrast=0.5):\n",
    "        super().__init__()\n",
    "        self.w_ssim = w_ssim\n",
    "        self.w_grad = w_grad\n",
    "        self.w_perc = w_perc        # INCREASED from 0.1 to 1.0\n",
    "        self.w_contrast = w_contrast # NEW TERM\n",
    "        \n",
    "        # Better perceptual network\n",
    "        from torchvision.models import vgg19\n",
    "        vgg = vgg19(pretrained=True).features[:16].to(device).eval()  # Up to relu3_1\n",
    "        for param in vgg.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.vgg = vgg\n",
    "    \n",
    "    def gradient_loss(self, fused, ct, mr):\n",
    "        \"\"\"Enhanced gradient preservation\"\"\"\n",
    "        def sobel_gradients(x):\n",
    "            kx = torch.tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], \n",
    "                             dtype=torch.float32).view(1, 1, 3, 3).to(x.device)\n",
    "            ky = torch.tensor([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], \n",
    "                             dtype=torch.float32).view(1, 1, 3, 3).to(x.device)\n",
    "            gx = F.conv2d(x, kx, padding=1)\n",
    "            gy = F.conv2d(x, ky, padding=1)\n",
    "            return torch.sqrt(gx**2 + gy**2 + 1e-8)\n",
    "        \n",
    "        grad_fused = sobel_gradients(fused)\n",
    "        grad_ct = sobel_gradients(ct)\n",
    "        grad_mr = sobel_gradients(mr)\n",
    "        grad_target = torch.max(grad_ct, grad_mr)  # Preserve strongest edges\n",
    "        \n",
    "        return F.mse_loss(grad_fused, grad_target)\n",
    "    \n",
    "    def perceptual_loss(self, fused, ct, mr):\n",
    "        \"\"\"Enhanced perceptual loss\"\"\"\n",
    "        # Convert to 3-channel for VGG\n",
    "        fused_3ch = fused.repeat(1, 3, 1, 1)\n",
    "        ct_3ch = ct.repeat(1, 3, 1, 1) \n",
    "        mr_3ch = mr.repeat(1, 3, 1, 1)\n",
    "        \n",
    "        # Extract features\n",
    "        fused_feat = self.vgg(fused_3ch)\n",
    "        ct_feat = self.vgg(ct_3ch)\n",
    "        mr_feat = self.vgg(mr_3ch)\n",
    "        \n",
    "        # Loss with both sources\n",
    "        loss = 0.5 * (F.mse_loss(fused_feat, ct_feat) + F.mse_loss(fused_feat, mr_feat))\n",
    "        return loss\n",
    "    \n",
    "    def contrast_loss(self, fused, ct, mr):\n",
    "        \"\"\"NEW: Preserve local contrast\"\"\"\n",
    "        def local_contrast(x):\n",
    "            # Laplacian kernel for edge detection\n",
    "            kernel = torch.tensor([[0, -1, 0], [-1, 4, -1], [0, -1, 0]], \n",
    "                                 dtype=torch.float32).view(1, 1, 3, 3).to(x.device)\n",
    "            return F.conv2d(x, kernel, padding=1)\n",
    "        \n",
    "        fused_contrast = torch.abs(local_contrast(fused))\n",
    "        ct_contrast = torch.abs(local_contrast(ct))\n",
    "        mr_contrast = torch.abs(local_contrast(mr))\n",
    "        target_contrast = torch.max(ct_contrast, mr_contrast)\n",
    "        \n",
    "        return F.mse_loss(fused_contrast, target_contrast)\n",
    "    \n",
    "    def ssim_loss(self, fused, ct, mr):\n",
    "        \"\"\"SSIM loss with both sources\"\"\"\n",
    "        # Simplified SSIM implementation\n",
    "        def simple_ssim(x, y):\n",
    "            mu_x = F.avg_pool2d(x, 3, 1, 1)\n",
    "            mu_y = F.avg_pool2d(y, 3, 1, 1)\n",
    "            sigma_x = F.avg_pool2d(x * x, 3, 1, 1) - mu_x * mu_x\n",
    "            sigma_y = F.avg_pool2d(y * y, 3, 1, 1) - mu_y * mu_y\n",
    "            sigma_xy = F.avg_pool2d(x * y, 3, 1, 1) - mu_x * mu_y\n",
    "            \n",
    "            c1, c2 = 0.01**2, 0.03**2\n",
    "            ssim = ((2*mu_x*mu_y + c1) * (2*sigma_xy + c2)) / ((mu_x**2 + mu_y**2 + c1) * (sigma_x + sigma_y + c2))\n",
    "            return ssim.mean()\n",
    "        \n",
    "        ssim_ct = simple_ssim(fused, ct)\n",
    "        ssim_mr = simple_ssim(fused, mr)\n",
    "        return 1 - 0.5 * (ssim_ct + ssim_mr)\n",
    "    \n",
    "    def forward(self, fused, ct, mr):\n",
    "        l_ssim = self.ssim_loss(fused, ct, mr)\n",
    "        l_grad = self.gradient_loss(fused, ct, mr)  \n",
    "        l_perc = self.perceptual_loss(fused, ct, mr)\n",
    "        l_contrast = self.contrast_loss(fused, ct, mr)\n",
    "        \n",
    "        total = (self.w_ssim * l_ssim + \n",
    "                self.w_grad * l_grad + \n",
    "                self.w_perc * l_perc + \n",
    "                self.w_contrast * l_contrast)\n",
    "        \n",
    "        return total, {\n",
    "            \"ssim\": l_ssim.item(),\n",
    "            \"grad\": l_grad.item(), \n",
    "            \"perc\": l_perc.item(),\n",
    "            \"contrast\": l_contrast.item()\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ Enhanced Loss Function Defined\")\n",
    "print(\"Key improvements:\")\n",
    "print(\"- Increased perceptual weight: 0.1 ‚Üí 1.0\")\n",
    "print(\"- Increased gradient weight: 1.0 ‚Üí 2.0\") \n",
    "print(\"- Added contrast preservation term\")\n",
    "print(\"- Better gradient and perceptual computations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b8595d",
   "metadata": {},
   "source": [
    "### **Priority 2: Training Improvements**\n",
    "\n",
    "#### **C) Better Training Configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55b19c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training Improvements Defined\n",
      "Key changes:\n",
      "- Larger batch size: 4 ‚Üí 8\n",
      "- More epochs: 20 ‚Üí 100\n",
      "- Lower learning rate: 1e-3 ‚Üí 1e-4\n",
      "- Better wavelet: haar ‚Üí db4\n",
      "- Added regularization and scheduling\n"
     ]
    }
   ],
   "source": [
    "# IMPROVEMENT 3: Enhanced Training Configuration\n",
    "class ImprovedConfig:\n",
    "    # Data improvements\n",
    "    batch_size = 8          # INCREASED from 4\n",
    "    epochs = 100            # INCREASED from 20  \n",
    "    lr = 1e-4              # DECREASED from 1e-3 (more stable)\n",
    "    val_split = 0.2        # INCREASED from 0.1 (more validation data)\n",
    "    \n",
    "    # Model improvements  \n",
    "    wave = 'db4'           # CHANGED from 'haar' (better reconstruction)\n",
    "    use_spatial_adaptive = True  # Use spatial-adaptive model\n",
    "    \n",
    "    # Loss rebalancing\n",
    "    w_ssim = 1.0           # Same\n",
    "    w_grad = 2.0           # INCREASED from 1.0\n",
    "    w_perc = 1.0           # INCREASED from 0.1\n",
    "    w_contrast = 0.5       # NEW TERM\n",
    "    \n",
    "    # Training enhancements\n",
    "    use_scheduler = True    # Add learning rate scheduling\n",
    "    weight_decay = 1e-4    # Add regularization\n",
    "    use_augmentation = True # Add data augmentation\n",
    "\n",
    "# IMPROVEMENT 4: Data Augmentation\n",
    "def create_augmented_loader(dataset, config):\n",
    "    # Add data augmentation for better generalization\n",
    "    import torchvision.transforms as transforms\n",
    "    \n",
    "    if config.use_augmentation:\n",
    "        # Define augmentations that preserve anatomical structure\n",
    "        transform = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(p=0.5),           # Mirror flip\n",
    "            transforms.RandomRotation(degrees=5, fill=0),     # Small rotations\n",
    "            transforms.ColorJitter(brightness=0.1, contrast=0.1)  # Intensity variations\n",
    "        ])\n",
    "        \n",
    "        # Apply to dataset (would need custom implementation)\n",
    "        print(\"Augmentation enabled: horizontal flip, rotation ¬±5¬∞, intensity jitter\")\n",
    "    else:\n",
    "        print(\"No augmentation\")\n",
    "    \n",
    "    return DataLoader(dataset, batch_size=config.batch_size, shuffle=True)\n",
    "\n",
    "# IMPROVEMENT 5: Better Optimization\n",
    "def create_improved_optimizer(model, config):\n",
    "    # \\\"\\\"\\\"Create optimizer with scheduling and regularization\\\"\\\"\\\"\n",
    "    \n",
    "    # Use AdamW with weight decay\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(), \n",
    "        lr=config.lr, \n",
    "        weight_decay=config.weight_decay\n",
    "    )\n",
    "    \n",
    "    # Add learning rate scheduling\n",
    "    if config.use_scheduler:\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer, T_max=config.epochs, eta_min=1e-6\n",
    "        )\n",
    "        print(f\"‚úÖ Optimizer: AdamW with lr={config.lr}, weight_decay={config.weight_decay}\")\n",
    "        print(f\"‚úÖ Scheduler: CosineAnnealing from {config.lr} to 1e-6\")\n",
    "    else:\n",
    "        scheduler = None\n",
    "        print(f\"‚úÖ Optimizer: AdamW with lr={config.lr}\")\n",
    "    \n",
    "    return optimizer, scheduler\n",
    "\n",
    "print(\"‚úÖ Training Improvements Defined\")\n",
    "print(\"Key changes:\")\n",
    "print(\"- Larger batch size: 4 ‚Üí 8\")\n",
    "print(\"- More epochs: 20 ‚Üí 100\") \n",
    "print(\"- Lower learning rate: 1e-3 ‚Üí 1e-4\")\n",
    "print(\"- Better wavelet: haar ‚Üí db4\")\n",
    "print(\"- Added regularization and scheduling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf9749f",
   "metadata": {},
   "source": [
    "### **Expected Performance Improvements**\n",
    "\n",
    "With these enhancements, you should expect:\n",
    "\n",
    "| Metric | Current | Expected | Improvement |\n",
    "|--------|---------|----------|-------------|\n",
    "| **Overall Score** | 0.554 | **0.65-0.75** | **+17-35%** |\n",
    "| **SSIM Average** | 0.739 | **0.80-0.85** | **+8-15%** |\n",
    "| **PSNR Average** | 15.48 | **18-22** | **+16-42%** |\n",
    "| **Edge Preservation** | 0.964 | **0.975-0.985** | **+1-2%** |\n",
    "| **Entropy** | 3.92 | **4.2-4.8** | **+7-23%** |\n",
    "\n",
    "### **Implementation Priority:**\n",
    "\n",
    "1. **üî• CRITICAL**: Enhanced Loss Function (biggest impact)\n",
    "2. **üî• CRITICAL**: Spatial-Adaptive Model (architectural improvement)  \n",
    "3. **‚ö° HIGH**: Training Configuration (more epochs, better optimization)\n",
    "4. **üìà MEDIUM**: Data Augmentation (generalization)\n",
    "5. **üî¨ LOW**: Multi-scale wavelets (refinement)\n",
    "\n",
    "### **Quick Win Strategy:**\n",
    "Start with **Enhanced Loss Function** only - this should give **+10-20%** improvement with minimal code changes!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec416383",
   "metadata": {},
   "source": [
    "## üéØ Next Steps - Implementation Guide\n",
    "\n",
    "### **Step 1: Quick Win - Enhanced Loss Function**\n",
    "Replace the current loss function in your training script with the enhanced version above. This alone should provide significant improvement.\n",
    "\n",
    "### **Step 2: Implement Spatial-Adaptive Model**  \n",
    "Replace `WaveletFusionNet` with `SpatialAdaptiveWaveletFusion` for location-aware fusion.\n",
    "\n",
    "### **Step 3: Update Training Configuration**\n",
    "Use the improved configuration with more epochs, better learning rate, and regularization.\n",
    "\n",
    "### **Step 4: Validation**\n",
    "Re-run this evaluation notebook on the improved model to measure performance gains.\n",
    "\n",
    "### **Files to Modify:**\n",
    "1. **Main training script**: Replace loss function and model\n",
    "2. **Training config**: Update hyperparameters\n",
    "3. **This notebook**: Test the improved model\n",
    "\n",
    "Would you like me to create a modified version of your training script with these improvements implemented?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
