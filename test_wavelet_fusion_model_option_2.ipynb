{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef050624",
   "metadata": {},
   "source": [
    "# Trainable Wavelet Fusion Model Option 2 - Testing and Evaluation\n",
    "\n",
    "This notebook tests the trained spatial-adaptive wavelet fusion model (Option 2) on sample CT-MRI image pairs and evaluates the fusion quality with comprehensive metrics and visualizations.\n",
    "\n",
    "## Key Features of Option 2 Model:\n",
    "- **Spatial-Adaptive Fusion**: Uses CNN-based masks for location-aware fusion\n",
    "- **Enhanced Loss Function**: Combines L1, SSIM, and gradient losses\n",
    "- **High-Frequency Detail Preservation**: Better edge and texture preservation\n",
    "- **Trainable Fusion Weights**: Learned spatial masks for optimal fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcaf711",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1d4cb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from typing import Tuple, List\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyWavelets and pytorch_wavelets for wavelet transforms\n",
    "from pytorch_wavelets import DWTForward, DWTInverse\n",
    "\n",
    "# Import evaluation metrics\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set matplotlib style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046dc4a1",
   "metadata": {},
   "source": [
    "## 2. Define Model Architecture and Evaluation Functions\n",
    "\n",
    "Define the spatial-adaptive wavelet fusion model and evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4719e27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveletFusionNetSpatial(nn.Module):\n",
    "    def __init__(self, wave='haar'):\n",
    "        super().__init__()\n",
    "        self.dwt = DWTForward(J=1, wave=wave)\n",
    "        self.idwt = DWTInverse(wave=wave)\n",
    "        self.mask_net = nn.Sequential(\n",
    "            nn.Conv2d(2,16,3,padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(16,32,3,padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(32,4,3,padding=1), nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, ct, mr):\n",
    "        # --- Ensure 4D ---\n",
    "        if ct.dim() == 3: ct = ct.unsqueeze(0)\n",
    "        if mr.dim() == 3: mr = mr.unsqueeze(0)\n",
    "\n",
    "        # --- DWT decomposition ---\n",
    "        ct_low, ct_high = self.dwt(ct)\n",
    "        mr_low, mr_high = self.dwt(mr)\n",
    "\n",
    "        # --- Split high-frequency channels ---\n",
    "        ct_lh, ct_hl, ct_hh = ct_high[0][:,:,0:1,:,:], ct_high[0][:,:,1:2,:,:], ct_high[0][:,:,2:3,:,:]\n",
    "        mr_lh, mr_hl, mr_hh = mr_high[0][:,:,0:1,:,:], mr_high[0][:,:,1:2,:,:], mr_high[0][:,:,2:3,:,:]\n",
    "        \n",
    "        # Squeeze the extra dimension to get [batch, channels, H, W]\n",
    "        ct_lh, ct_hl, ct_hh = ct_lh.squeeze(2), ct_hl.squeeze(2), ct_hh.squeeze(2)\n",
    "        mr_lh, mr_hl, mr_hh = mr_lh.squeeze(2), mr_hl.squeeze(2), mr_hh.squeeze(2)\n",
    "\n",
    "        # --- Low-frequency mask input ---\n",
    "        low_stack = torch.cat([ct_low, mr_low], dim=1)\n",
    "        masks_low = self.mask_net(low_stack)\n",
    "        mL, mLH_small, mHL_small, mHH_small = masks_low[:,0:1], masks_low[:,1:2], masks_low[:,2:3], masks_low[:,3:4]\n",
    "        \n",
    "        # Resize high-frequency masks to match high-frequency component dimensions\n",
    "        high_freq_size = (ct_lh.shape[2], ct_lh.shape[3])\n",
    "        mLH = F.interpolate(mLH_small, size=high_freq_size, mode='bilinear', align_corners=False)\n",
    "        mHL = F.interpolate(mHL_small, size=high_freq_size, mode='bilinear', align_corners=False)\n",
    "        mHH = F.interpolate(mHH_small, size=high_freq_size, mode='bilinear', align_corners=False)\n",
    "\n",
    "        # --- Fuse low-frequency ---\n",
    "        fused_low = mL*ct_low + (1-mL)*mr_low\n",
    "\n",
    "        # --- Fuse high-frequency ---\n",
    "        fused_lh = mLH*ct_lh + (1-mLH)*mr_lh\n",
    "        fused_hl = mHL*ct_hl + (1-mHL)*mr_hl\n",
    "        fused_hh = mHH*ct_hh + (1-mHH)*mr_hh\n",
    "        \n",
    "        # Stack them back to the original format for inverse DWT\n",
    "        fused_high = torch.stack([fused_lh, fused_hl, fused_hh], dim=2)\n",
    "\n",
    "        # --- Inverse DWT ---\n",
    "        fused = self.idwt((fused_low, [fused_high]))\n",
    "        return fused, {'mL': mL, 'mLH': mLH, 'mHL': mHL, 'mHH': mHH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d0c1a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive evaluation functions\n",
    "def calculate_ssim(img1, img2):\n",
    "    \"\"\"Calculate SSIM between two images.\"\"\"\n",
    "    return ssim(img1, img2, data_range=1.0)\n",
    "\n",
    "def calculate_psnr(img1, img2):\n",
    "    \"\"\"Calculate PSNR between two images.\"\"\"\n",
    "    mse = np.mean((img1 - img2) ** 2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    return 20 * np.log10(1.0 / np.sqrt(mse))\n",
    "\n",
    "def calculate_gradient_magnitude(img):\n",
    "    \"\"\"Calculate gradient magnitude using Sobel operators.\"\"\"\n",
    "    img_uint8 = (img * 255).astype(np.uint8)\n",
    "    grad_x = cv2.Sobel(img_uint8, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    grad_y = cv2.Sobel(img_uint8, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    return np.sqrt(grad_x**2 + grad_y**2) / 255.0\n",
    "\n",
    "def calculate_edge_preservation(fused, ct, mri):\n",
    "    \"\"\"Calculate edge preservation metric.\"\"\"\n",
    "    grad_fused = calculate_gradient_magnitude(fused)\n",
    "    grad_ct = calculate_gradient_magnitude(ct)\n",
    "    grad_mri = calculate_gradient_magnitude(mri)\n",
    "    grad_max = np.maximum(grad_ct, grad_mri)\n",
    "    correlation = np.corrcoef(grad_fused.flatten(), grad_max.flatten())[0, 1]\n",
    "    return correlation if not np.isnan(correlation) else 0.0\n",
    "\n",
    "def calculate_entropy(img):\n",
    "    \"\"\"Calculate image entropy.\"\"\"\n",
    "    img_uint8 = (img * 255).astype(np.uint8)\n",
    "    hist, _ = np.histogram(img_uint8, bins=256, range=(0, 256))\n",
    "    hist = hist / hist.sum()\n",
    "    hist = hist[hist > 0]\n",
    "    return -np.sum(hist * np.log2(hist))\n",
    "\n",
    "def calculate_mutual_information(img1, img2):\n",
    "    \"\"\"Calculate mutual information between two images.\"\"\"\n",
    "    img1_uint8 = (img1 * 255).astype(np.uint8)\n",
    "    img2_uint8 = (img2 * 255).astype(np.uint8)\n",
    "    hist_2d, _, _ = np.histogram2d(img1_uint8.flatten(), img2_uint8.flatten(), bins=256)\n",
    "    hist_2d = hist_2d / hist_2d.sum()\n",
    "    hist_1 = hist_2d.sum(axis=1)\n",
    "    hist_2 = hist_2d.sum(axis=0)\n",
    "    mi = 0.0\n",
    "    for i in range(256):\n",
    "        for j in range(256):\n",
    "            if hist_2d[i, j] > 0 and hist_1[i] > 0 and hist_2[j] > 0:\n",
    "                mi += hist_2d[i, j] * np.log2(hist_2d[i, j] / (hist_1[i] * hist_2[j]))\n",
    "    return mi\n",
    "\n",
    "def evaluate_fusion_quality(fused, ct, mri):\n",
    "    \"\"\"Comprehensive evaluation of fusion quality.\"\"\"\n",
    "    if fused is None:\n",
    "        return {}\n",
    "    \n",
    "    metrics = {}\n",
    "    metrics['SSIM_CT'] = calculate_ssim(fused, ct)\n",
    "    metrics['SSIM_MRI'] = calculate_ssim(fused, mri)\n",
    "    metrics['SSIM_Avg'] = (metrics['SSIM_CT'] + metrics['SSIM_MRI']) / 2\n",
    "    metrics['PSNR_CT'] = calculate_psnr(fused, ct)\n",
    "    metrics['PSNR_MRI'] = calculate_psnr(fused, mri)\n",
    "    metrics['PSNR_Avg'] = (metrics['PSNR_CT'] + metrics['PSNR_MRI']) / 2\n",
    "    metrics['Edge_Preservation'] = calculate_edge_preservation(fused, ct, mri)\n",
    "    metrics['Entropy'] = calculate_entropy(fused)\n",
    "    metrics['MI_CT'] = calculate_mutual_information(fused, ct)\n",
    "    metrics['MI_MRI'] = calculate_mutual_information(fused, mri)\n",
    "    metrics['MI_Avg'] = (metrics['MI_CT'] + metrics['MI_MRI']) / 2\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f6deeb",
   "metadata": {},
   "source": [
    "## 3. Load the Trained Model\n",
    "\n",
    "Load the trained spatial-adaptive wavelet fusion model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96e88087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Model checkpoint not found at checkpoints_enhanced/wavelet_fusion_spatial_best.pt\n",
      "Please train the model first using the training notebook.\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "model_path = 'checkpoints_enhanced/wavelet_fusion_spatial_best.pt'\n",
    "if os.path.exists(model_path):\n",
    "    model = WaveletFusionNetSpatial(wave='haar').to(device)\n",
    "    \n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    \n",
    "    # Load model state\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"âœ… Model loaded successfully from {model_path}\")\n",
    "    print(f\"   Training epoch: {checkpoint['epoch']}\")\n",
    "    print(f\"   Best loss: {checkpoint['best_loss']:.4f}\")\n",
    "    print(f\"   Model type: {checkpoint['model_config']['model_type']}\")\n",
    "    print(f\"   Loss weights: {checkpoint['model_config']['loss_weights']}\")\n",
    "    \n",
    "    # Load training history if available\n",
    "    history_path = 'checkpoints_enhanced/training_history.pt'\n",
    "    if os.path.exists(history_path):\n",
    "        training_history = torch.load(history_path, map_location='cpu')\n",
    "        print(f\"   Training history loaded: {len(training_history['epoch_metrics'])} epochs\")\n",
    "        \n",
    "        # Plot training history\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        \n",
    "        plt.subplot(1, 3, 1)\n",
    "        epochs_range = range(1, len(training_history['epoch_metrics']) + 1)\n",
    "        plt.plot(epochs_range, [m['total'] for m in training_history['epoch_metrics']], 'b-', linewidth=2)\n",
    "        plt.axvline(x=training_history['best_epoch'], color='red', linestyle='--', alpha=0.7, label=f'Best Epoch ({training_history[\"best_epoch\"]})')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Total Loss')\n",
    "        plt.title('Training Loss Curve')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.plot(epochs_range, [m['l1'] for m in training_history['epoch_metrics']], 'r-', label='L1 Loss')\n",
    "        plt.plot(epochs_range, [m['ssim'] for m in training_history['epoch_metrics']], 'g-', label='SSIM Loss')\n",
    "        plt.plot(epochs_range, [m['gradient'] for m in training_history['epoch_metrics']], 'm-', label='Gradient Loss')\n",
    "        plt.axvline(x=training_history['best_epoch'], color='red', linestyle='--', alpha=0.7)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss Components')\n",
    "        plt.title('Loss Components')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.plot(epochs_range, [m['l1_ct'] for m in training_history['epoch_metrics']], 'r-', label='CT L1')\n",
    "        plt.plot(epochs_range, [m['l1_mr'] for m in training_history['epoch_metrics']], 'b-', label='MRI L1')\n",
    "        plt.axvline(x=training_history['best_epoch'], color='red', linestyle='--', alpha=0.7)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Reconstruction Loss')\n",
    "        plt.title('CT vs MRI Loss Balance')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "else:\n",
    "    print(f\"âŒ Model checkpoint not found at {model_path}\")\n",
    "    print(\"Please train the model first using the training notebook.\")\n",
    "    model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debc0758",
   "metadata": {},
   "source": [
    "## 4. Load and Preprocess Test Images\n",
    "\n",
    "Define helper functions to load and preprocess CT-MRI image pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5c81908",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ct_test_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 46\u001b[0m\n\u001b[1;32m     43\u001b[0m ct_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHarvard-Medical-Image-Fusion-Datasets/MyDatasets/CT-MRI/test/CT\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     44\u001b[0m mri_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHarvard-Medical-Image-Fusion-Datasets/MyDatasets/CT-MRI/test/MRI\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 46\u001b[0m test_pairs \u001b[38;5;241m=\u001b[39m get_test_image_pairs(\u001b[43mct_test_dir\u001b[49m, mri_test_dir, num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(test_pairs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m test image pairs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (ct_path, mri_path) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(test_pairs[:\u001b[38;5;241m3\u001b[39m]):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ct_test_dir' is not defined"
     ]
    }
   ],
   "source": [
    "def load_image_pair(ct_path, mri_path, resize=None):\n",
    "    \"\"\"Load and preprocess a CT-MRI image pair.\"\"\"\n",
    "    ct = cv2.imread(ct_path, cv2.IMREAD_GRAYSCALE)\n",
    "    mri = cv2.imread(mri_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if ct is None or mri is None:\n",
    "        raise FileNotFoundError(f\"Could not load images: {ct_path}, {mri_path}\")\n",
    "    \n",
    "    if resize is not None:\n",
    "        H, W = resize\n",
    "        ct = cv2.resize(ct, (W, H), interpolation=cv2.INTER_AREA)\n",
    "        mri = cv2.resize(mri, (W, H), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # Normalize to [0, 1]\n",
    "    ct = ct.astype(np.float32)\n",
    "    mri = mri.astype(np.float32)\n",
    "    if ct.max() > 1.0: ct /= 255.0\n",
    "    if mri.max() > 1.0: mri /= 255.0\n",
    "    \n",
    "    return ct, mri\n",
    "\n",
    "def get_test_image_pairs(ct_dir, mri_dir, num_samples=5):\n",
    "    \"\"\"Get a list of test image pairs.\"\"\"\n",
    "    ct_files = sorted(glob.glob(os.path.join(ct_dir, '*.png')))\n",
    "    mri_files = sorted(glob.glob(os.path.join(mri_dir, '*.png')))\n",
    "    \n",
    "    # Match files by basename\n",
    "    pairs = []\n",
    "    for ct_file in ct_files:\n",
    "        ct_basename = os.path.basename(ct_file)\n",
    "        mri_file = os.path.join(mri_dir, ct_basename)\n",
    "        if os.path.exists(mri_file):\n",
    "            pairs.append((ct_file, mri_file))\n",
    "    \n",
    "    # Select a subset for testing\n",
    "    if len(pairs) > num_samples:\n",
    "        indices = np.linspace(0, len(pairs)-1, num_samples, dtype=int)\n",
    "        pairs = [pairs[i] for i in indices]\n",
    "    \n",
    "    return pairs\n",
    "\n",
    "# Get test image pairs\n",
    "ct_test_dir = 'Harvard-Medical-Image-Fusion-Datasets/MyDatasets/CT-MRI/test/CT'\n",
    "mri_test_dir = 'Harvard-Medical-Image-Fusion-Datasets/MyDatasets/CT-MRI/test/MRI'\n",
    "\n",
    "test_pairs = get_test_image_pairs(ct_test_dir, mri_test_dir, num_samples=6)\n",
    "print(f\"Found {len(test_pairs)} test image pairs\")\n",
    "\n",
    "for i, (ct_path, mri_path) in enumerate(test_pairs[:3]):\n",
    "    print(f\"  Pair {i+1}: {os.path.basename(ct_path)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aec1633",
   "metadata": {},
   "source": [
    "## 5. Perform Image Fusion\n",
    "\n",
    "Define fusion methods including the trained model and baseline methods for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36a9c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse_with_spatial_model(model, ct, mri):\n",
    "    \"\"\"Fuse images using the trained spatial-adaptive model.\"\"\"\n",
    "    if model is None:\n",
    "        return None, None\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Convert to tensors and add batch dimension\n",
    "        ct_tensor = torch.from_numpy(ct)[None, None, ...].to(device)\n",
    "        mri_tensor = torch.from_numpy(mri)[None, None, ...].to(device)\n",
    "        \n",
    "        # Perform fusion and get masks\n",
    "        fused_tensor, masks = model(ct_tensor, mri_tensor)\n",
    "        \n",
    "        # Convert back to numpy\n",
    "        fused = fused_tensor.squeeze().cpu().numpy()\n",
    "        \n",
    "        # Convert masks to numpy\n",
    "        mask_data = {}\n",
    "        for key, mask_tensor in masks.items():\n",
    "            mask_data[key] = mask_tensor.squeeze().cpu().numpy()\n",
    "        \n",
    "        return np.clip(fused, 0, 1), mask_data\n",
    "\n",
    "def fuse_average(ct, mri):\n",
    "    \"\"\"Simple average fusion.\"\"\"\n",
    "    return 0.5 * (ct + mri)\n",
    "\n",
    "def fuse_max(ct, mri):\n",
    "    \"\"\"Max-based fusion.\"\"\"\n",
    "    return np.maximum(ct, mri)\n",
    "\n",
    "def fuse_weighted(ct, mri, weight=0.6):\n",
    "    \"\"\"Weighted fusion favoring CT.\"\"\"\n",
    "    return weight * ct + (1 - weight) * mri\n",
    "\n",
    "# Test fusion on the first image pair\n",
    "if test_pairs and model is not None:\n",
    "    ct_path, mri_path = test_pairs[0]\n",
    "    ct_img, mri_img = load_image_pair(ct_path, mri_path)\n",
    "    \n",
    "    print(f\"Testing fusion on: {os.path.basename(ct_path)}\")\n",
    "    print(f\"Image shape: {ct_img.shape}\")\n",
    "    print(f\"CT range: [{ct_img.min():.3f}, {ct_img.max():.3f}]\")\n",
    "    print(f\"MRI range: [{mri_img.min():.3f}, {mri_img.max():.3f}]\")\n",
    "    \n",
    "    # Test spatial-adaptive fusion\n",
    "    fused_spatial, spatial_masks = fuse_with_spatial_model(model, ct_img, mri_img)\n",
    "    if fused_spatial is not None:\n",
    "        print(f\"Fused range: [{fused_spatial.min():.3f}, {fused_spatial.max():.3f}]\")\n",
    "        print(\"âœ… Spatial-adaptive fusion successful!\")\n",
    "        \n",
    "        # Display mask statistics\n",
    "        print(\"\\nLearned Spatial Masks Statistics:\")\n",
    "        for mask_name, mask in spatial_masks.items():\n",
    "            print(f\"  {mask_name}: mean={mask.mean():.3f}, std={mask.std():.3f}, range=[{mask.min():.3f}, {mask.max():.3f}]\")\n",
    "    else:\n",
    "        print(\"âŒ Spatial fusion failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f20694b",
   "metadata": {},
   "source": [
    "## 6. Display Fusion Results with Spatial Masks\n",
    "\n",
    "Visualize the fusion results and learned spatial masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff32699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_spatial_fusion_results(ct, mri, fused, masks, figsize=(20, 12)):\n",
    "    \"\"\"Display original images, fusion result, and learned spatial masks.\"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Original images and fusion result\n",
    "    plt.subplot(3, 4, 1)\n",
    "    plt.imshow(ct, cmap='gray')\n",
    "    plt.title('CT (Source A)', fontsize=14, fontweight='bold')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(3, 4, 2)\n",
    "    plt.imshow(mri, cmap='gray')\n",
    "    plt.title('MRI (Source B)', fontsize=14, fontweight='bold')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(3, 4, 3)\n",
    "    plt.imshow(fused, cmap='gray')\n",
    "    plt.title('Spatial-Adaptive Fusion', fontsize=14, fontweight='bold')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Difference map\n",
    "    plt.subplot(3, 4, 4)\n",
    "    diff = np.abs(fused - 0.5 * (ct + mri))\n",
    "    plt.imshow(diff, cmap='hot')\n",
    "    plt.title('Difference from Average\\n(Adaptive Enhancement)', fontsize=12)\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Spatial masks\n",
    "    mask_titles = {\n",
    "        'mL': 'Low-frequency Mask\\n(CT=Red, MRI=Blue)',\n",
    "        'mLH': 'LH Detail Mask\\n(CT=Red, MRI=Blue)', \n",
    "        'mHL': 'HL Detail Mask\\n(CT=Red, MRI=Blue)',\n",
    "        'mHH': 'HH Detail Mask\\n(CT=Red, MRI=Blue)'\n",
    "    }\n",
    "    \n",
    "    for i, (mask_name, mask_title) in enumerate(mask_titles.items()):\n",
    "        plt.subplot(3, 4, 5 + i)\n",
    "        mask = masks[mask_name]\n",
    "        plt.imshow(mask, cmap='RdBu_r', vmin=0, vmax=1)\n",
    "        plt.title(mask_title, fontsize=11)\n",
    "        plt.colorbar()\n",
    "        plt.axis('off')\n",
    "    \n",
    "    # Mask analysis\n",
    "    plt.subplot(3, 4, 9)\n",
    "    mask_names = list(masks.keys())\n",
    "    mask_means = [masks[name].mean() for name in mask_names]\n",
    "    bars = plt.bar(range(len(mask_names)), mask_means, color=['red', 'blue', 'green', 'orange'])\n",
    "    plt.axhline(y=0.5, color='black', linestyle='--', alpha=0.7, label='Equal Weight')\n",
    "    plt.xlabel('Frequency Band')\n",
    "    plt.ylabel('Average CT Weight')\n",
    "    plt.title('Learned Fusion Preferences\\n(>0.5 favors CT, <0.5 favors MRI)')\n",
    "    plt.xticks(range(len(mask_names)), ['Low', 'LH', 'HL', 'HH'])\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, val in zip(bars, mask_means):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                f'{val:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    # Spatial distribution analysis\n",
    "    plt.subplot(3, 4, 10)\n",
    "    # Create RGB image showing spatial preference\n",
    "    h, w = masks['mL'].shape\n",
    "    rgb_mask = np.zeros((h, w, 3))\n",
    "    rgb_mask[:, :, 0] = masks['mL']  # Red channel for CT preference\n",
    "    rgb_mask[:, :, 2] = 1 - masks['mL']  # Blue channel for MRI preference\n",
    "    plt.imshow(rgb_mask)\n",
    "    plt.title('Spatial Fusion Map\\n(Red=CT, Blue=MRI, Purple=Mixed)')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Mask histogram\n",
    "    plt.subplot(3, 4, 11)\n",
    "    for i, (name, mask) in enumerate(masks.items()):\n",
    "        plt.hist(mask.flatten(), bins=50, alpha=0.7, label=name, density=True)\n",
    "    plt.xlabel('Mask Value (CT Weight)')\n",
    "    plt.ylabel('Density')\n",
    "    plt.title('Mask Value Distributions')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Quality metrics\n",
    "    plt.subplot(3, 4, 12)\n",
    "    metrics = evaluate_fusion_quality(fused, ct, mri)\n",
    "    metrics_names = ['SSIM_Avg', 'PSNR_Avg', 'Edge_Preservation', 'Entropy']\n",
    "    metrics_values = [\n",
    "        metrics['SSIM_Avg'], \n",
    "        metrics['PSNR_Avg']/30,  # Normalize PSNR\n",
    "        metrics['Edge_Preservation'], \n",
    "        metrics['Entropy']/8     # Normalize entropy\n",
    "    ]\n",
    "    \n",
    "    bars = plt.bar(range(len(metrics_names)), metrics_values, \n",
    "                   color=['blue', 'green', 'red', 'orange'])\n",
    "    plt.xlabel('Quality Metrics')\n",
    "    plt.ylabel('Normalized Score')\n",
    "    plt.title('Fusion Quality Assessment')\n",
    "    plt.xticks(range(len(metrics_names)), ['SSIM', 'PSNR', 'Edge', 'Entropy'], rotation=45)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (bar, val) in enumerate(zip(bars, metrics_values)):\n",
    "        actual_val = [metrics['SSIM_Avg'], metrics['PSNR_Avg'], metrics['Edge_Preservation'], metrics['Entropy']][i]\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                f'{actual_val:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Display results for the first test image\n",
    "if test_pairs and model is not None and fused_spatial is not None:\n",
    "    display_spatial_fusion_results(ct_img, mri_img, fused_spatial, spatial_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e510b835",
   "metadata": {},
   "source": [
    "## 7. Comprehensive Comparison Analysis\n",
    "\n",
    "Compare the spatial-adaptive model with baseline fusion methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36f0e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive comparison of fusion methods\n",
    "print(\"=\" * 90)\n",
    "print(\"COMPARATIVE ANALYSIS: SPATIAL-ADAPTIVE MODEL vs BASELINE METHODS\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "def comprehensive_fusion_comparison(model, test_pairs, num_tests=5):\n",
    "    \"\"\"Compare spatial-adaptive fusion with baseline methods.\"\"\"\n",
    "    \n",
    "    test_results = []\n",
    "    num_test_images = min(num_tests, len(test_pairs))\n",
    "    \n",
    "    print(f\"Testing {num_test_images} image pairs...\\n\")\n",
    "    \n",
    "    for test_idx in range(num_test_images):\n",
    "        ct_path, mri_path = test_pairs[test_idx]\n",
    "        ct_img, mri_img = load_image_pair(ct_path, mri_path)\n",
    "        \n",
    "        print(f\"Test Image {test_idx + 1}: {os.path.basename(ct_path)}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Different fusion methods\n",
    "        fusion_methods = {}\n",
    "        \n",
    "        # Spatial-adaptive model\n",
    "        if model is not None:\n",
    "            fused_spatial, masks = fuse_with_spatial_model(model, ct_img, mri_img)\n",
    "            if fused_spatial is not None:\n",
    "                fusion_methods['Spatial-Adaptive Model'] = fused_spatial\n",
    "        \n",
    "        # Baseline methods\n",
    "        fusion_methods['Average'] = fuse_average(ct_img, mri_img)\n",
    "        fusion_methods['Maximum'] = fuse_max(ct_img, mri_img)\n",
    "        fusion_methods['Weighted (0.6)'] = fuse_weighted(ct_img, mri_img, 0.6)\n",
    "        \n",
    "        # Evaluate each method\n",
    "        method_results = {}\n",
    "        for method_name, fused_img in fusion_methods.items():\n",
    "            metrics = evaluate_fusion_quality(fused_img, ct_img, mri_img)\n",
    "            method_results[method_name] = metrics\n",
    "            \n",
    "            print(f\"  {method_name:20s}: SSIM={metrics['SSIM_Avg']:.3f}, \"\n",
    "                  f\"PSNR={metrics['PSNR_Avg']:.1f}dB, \"\n",
    "                  f\"Edge={metrics['Edge_Preservation']:.3f}, \"\n",
    "                  f\"Entropy={metrics['Entropy']:.2f}\")\n",
    "        \n",
    "        test_results.append({\n",
    "            'image_idx': test_idx,\n",
    "            'image_name': os.path.basename(ct_path),\n",
    "            'methods': method_results,\n",
    "            'ct_img': ct_img,\n",
    "            'mri_img': mri_img,\n",
    "            'fusion_results': fusion_methods\n",
    "        })\n",
    "        print()\n",
    "    \n",
    "    return test_results\n",
    "\n",
    "# Perform comprehensive comparison\n",
    "if model is not None:\n",
    "    comparison_results = comprehensive_fusion_comparison(model, test_pairs, num_tests=5)\n",
    "    \n",
    "    # Aggregate statistics\n",
    "    print(\"AGGREGATE PERFORMANCE STATISTICS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    metrics_names = ['SSIM_Avg', 'PSNR_Avg', 'Edge_Preservation', 'Entropy', 'MI_Avg']\n",
    "    method_names = list(comparison_results[0]['methods'].keys())\n",
    "    \n",
    "    aggregate_stats = {}\n",
    "    for method in method_names:\n",
    "        aggregate_stats[method] = {}\n",
    "        for metric in metrics_names:\n",
    "            values = [result['methods'][method][metric] for result in comparison_results]\n",
    "            aggregate_stats[method][metric] = {\n",
    "                'mean': np.mean(values),\n",
    "                'std': np.std(values),\n",
    "                'min': np.min(values),\n",
    "                'max': np.max(values)\n",
    "            }\n",
    "    \n",
    "    # Display aggregate statistics\n",
    "    for method in method_names:\n",
    "        print(f\"\\n{method}:\")\n",
    "        print(f\"  SSIM:      {aggregate_stats[method]['SSIM_Avg']['mean']:.3f} Â± {aggregate_stats[method]['SSIM_Avg']['std']:.3f}\")\n",
    "        print(f\"  PSNR:      {aggregate_stats[method]['PSNR_Avg']['mean']:.1f} Â± {aggregate_stats[method]['PSNR_Avg']['std']:.1f} dB\")\n",
    "        print(f\"  Edge Pres: {aggregate_stats[method]['Edge_Preservation']['mean']:.3f} Â± {aggregate_stats[method]['Edge_Preservation']['std']:.3f}\")\n",
    "        print(f\"  Entropy:   {aggregate_stats[method]['Entropy']['mean']:.2f} Â± {aggregate_stats[method]['Entropy']['std']:.2f} bits\")\n",
    "        print(f\"  MI:        {aggregate_stats[method]['MI_Avg']['mean']:.3f} Â± {aggregate_stats[method]['MI_Avg']['std']:.3f} bits\")\n",
    "    \n",
    "    # Performance ranking\n",
    "    print(f\"\\nPERFORMANCE RANKING\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    for metric in metrics_names:\n",
    "        print(f\"\\nBest {metric}:\")\n",
    "        sorted_methods = sorted(method_names, \n",
    "                               key=lambda x: aggregate_stats[x][metric]['mean'], \n",
    "                               reverse=True)\n",
    "        for i, method in enumerate(sorted_methods, 1):\n",
    "            value = aggregate_stats[method][metric]['mean']\n",
    "            print(f\"  {i}. {method:25s}: {value:.3f}\")\n",
    "    \n",
    "    # Overall quality score\n",
    "    overall_scores = {}\n",
    "    for method in method_names:\n",
    "        score = (0.3 * aggregate_stats[method]['SSIM_Avg']['mean'] +\n",
    "                 0.25 * min(aggregate_stats[method]['PSNR_Avg']['mean']/30, 1.0) +\n",
    "                 0.25 * aggregate_stats[method]['Edge_Preservation']['mean'] +\n",
    "                 0.1 * min(aggregate_stats[method]['Entropy']['mean']/8, 1.0) +\n",
    "                 0.1 * min(aggregate_stats[method]['MI_Avg']['mean']/3, 1.0))\n",
    "        overall_scores[method] = score\n",
    "    \n",
    "    best_overall = max(overall_scores, key=overall_scores.get)\n",
    "    print(f\"\\nOVERALL PERFORMANCE RANKING:\")\n",
    "    print(\"-\" * 40)\n",
    "    sorted_overall = sorted(overall_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    for i, (method, score) in enumerate(sorted_overall, 1):\n",
    "        print(f\"  {i}. {method:25s}: {score:.3f}\")\n",
    "    \n",
    "    print(f\"\\nðŸ† Best Overall Method: {best_overall}\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ Model not available for comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e22e4ab",
   "metadata": {},
   "source": [
    "## 8. Visualization of Comparative Results\n",
    "\n",
    "Create comprehensive visualizations comparing all fusion methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57f85aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model is not None and 'comparison_results' in locals():\n",
    "    # Visualization of comparative results\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    \n",
    "    # Performance comparison charts\n",
    "    metrics_for_viz = ['SSIM_Avg', 'PSNR_Avg', 'Edge_Preservation', 'Entropy']\n",
    "    \n",
    "    for i, metric in enumerate(metrics_for_viz):\n",
    "        plt.subplot(3, 4, i + 1)\n",
    "        x_pos = np.arange(len(method_names))\n",
    "        means = [aggregate_stats[method][metric]['mean'] for method in method_names]\n",
    "        stds = [aggregate_stats[method][metric]['std'] for method in method_names]\n",
    "        \n",
    "        colors = ['red' if 'Spatial' in method else 'lightblue' for method in method_names]\n",
    "        bars = plt.bar(x_pos, means, yerr=stds, capsize=5, color=colors, edgecolor='black')\n",
    "        \n",
    "        plt.xlabel('Methods')\n",
    "        plt.ylabel(metric.replace('_', ' '))\n",
    "        plt.title(f'{metric.replace(\"_\", \" \")} Comparison')\n",
    "        plt.xticks(x_pos, [m.replace(' ', '\\n') for m in method_names], rotation=45, fontsize=9)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Highlight best performance\n",
    "        best_idx = means.index(max(means))\n",
    "        bars[best_idx].set_color('gold')\n",
    "        bars[best_idx].set_edgecolor('red')\n",
    "        bars[best_idx].set_linewidth(2)\n",
    "    \n",
    "    # Normalized metrics radar-style comparison\n",
    "    plt.subplot(3, 4, 5)\n",
    "    normalized_stats = {}\n",
    "    for method in method_names:\n",
    "        normalized_stats[method] = []\n",
    "        for metric in metrics_for_viz:\n",
    "            value = aggregate_stats[method][metric]['mean']\n",
    "            if metric == 'PSNR_Avg':\n",
    "                normalized_value = min(value / 30, 1.0)\n",
    "            elif metric == 'Entropy':\n",
    "                normalized_value = min(value / 8, 1.0)\n",
    "            else:\n",
    "                normalized_value = value\n",
    "            normalized_stats[method].append(normalized_value)\n",
    "    \n",
    "    width = 0.2\n",
    "    x = np.arange(len(metrics_for_viz))\n",
    "    for i, method in enumerate(method_names):\n",
    "        color = 'red' if 'Spatial' in method else f'C{i}'\n",
    "        plt.bar(x + i*width, normalized_stats[method], width, label=method, alpha=0.8, color=color)\n",
    "    \n",
    "    plt.xlabel('Metrics')\n",
    "    plt.ylabel('Normalized Score')\n",
    "    plt.title('Normalized Performance Comparison')\n",
    "    plt.xticks(x + width*1.5, ['SSIM', 'PSNR', 'Edge', 'Entropy'])\n",
    "    plt.legend(fontsize=8)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Sample fusion results\n",
    "    sample_idx = 0\n",
    "    sample_result = comparison_results[sample_idx]\n",
    "    \n",
    "    plt.subplot(3, 4, 6)\n",
    "    plt.imshow(sample_result['ct_img'], cmap='gray')\n",
    "    plt.title(f'CT Input\\n({sample_result[\"image_name\"]})')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(3, 4, 7)\n",
    "    plt.imshow(sample_result['mri_img'], cmap='gray')\n",
    "    plt.title('MRI Input')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(3, 4, 8)\n",
    "    if 'Spatial-Adaptive Model' in sample_result['fusion_results']:\n",
    "        plt.imshow(sample_result['fusion_results']['Spatial-Adaptive Model'], cmap='gray')\n",
    "        plt.title('Spatial-Adaptive Fusion')\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'Model\\nNot Available', ha='center', va='center', transform=plt.gca().transAxes)\n",
    "        plt.title('Spatial-Adaptive Fusion')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Additional sample results\n",
    "    baseline_methods = [m for m in method_names if 'Spatial' not in m]\n",
    "    for i, method in enumerate(baseline_methods[:4]):\n",
    "        plt.subplot(3, 4, 9 + i)\n",
    "        plt.imshow(sample_result['fusion_results'][method], cmap='gray')\n",
    "        plt.title(method.replace(' ', '\\n'))\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary statistics table\n",
    "    print(f\"\\n\" + \"FINAL PERFORMANCE SUMMARY\".center(80, \"=\"))\n",
    "    print(f\"\\nModel Performance Analysis:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    if 'Spatial-Adaptive Model' in method_names:\n",
    "        spatial_stats = aggregate_stats['Spatial-Adaptive Model']\n",
    "        print(f\"Spatial-Adaptive Model Performance:\")\n",
    "        print(f\"  SSIM:           {spatial_stats['SSIM_Avg']['mean']:.3f} Â± {spatial_stats['SSIM_Avg']['std']:.3f}\")\n",
    "        print(f\"  PSNR:           {spatial_stats['PSNR_Avg']['mean']:.1f} Â± {spatial_stats['PSNR_Avg']['std']:.1f} dB\")\n",
    "        print(f\"  Edge Preservation: {spatial_stats['Edge_Preservation']['mean']:.3f} Â± {spatial_stats['Edge_Preservation']['std']:.3f}\")\n",
    "        print(f\"  Information Content: {spatial_stats['Entropy']['mean']:.2f} Â± {spatial_stats['Entropy']['std']:.2f} bits\")\n",
    "        \n",
    "        # Performance improvement analysis\n",
    "        print(f\"\\nImprovement over baselines:\")\n",
    "        for baseline in ['Average', 'Maximum', 'Weighted (0.6)']:\n",
    "            if baseline in aggregate_stats:\n",
    "                ssim_improvement = ((spatial_stats['SSIM_Avg']['mean'] - aggregate_stats[baseline]['SSIM_Avg']['mean']) / \n",
    "                                   aggregate_stats[baseline]['SSIM_Avg']['mean'] * 100)\n",
    "                psnr_improvement = spatial_stats['PSNR_Avg']['mean'] - aggregate_stats[baseline]['PSNR_Avg']['mean']\n",
    "                print(f\"  vs {baseline:12s}: SSIM +{ssim_improvement:+.1f}%, PSNR +{psnr_improvement:+.1f}dB\")\n",
    "    \n",
    "    print(f\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecdfb37",
   "metadata": {},
   "source": [
    "## 9. Model Analysis and Insights\n",
    "\n",
    "Analyze the learned spatial masks and fusion behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691c0f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model is not None and 'comparison_results' in locals():\n",
    "    print(\"=\" * 80)\n",
    "    print(\"SPATIAL-ADAPTIVE MODEL ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Analyze spatial masks across multiple images\n",
    "    mask_analysis = {'mL': [], 'mLH': [], 'mHL': [], 'mHH': []}\n",
    "    fusion_preferences = []\n",
    "    \n",
    "    print(\"Analyzing learned spatial masks across test images...\\n\")\n",
    "    \n",
    "    for i, result in enumerate(comparison_results):\n",
    "        ct_img = result['ct_img']\n",
    "        mri_img = result['mri_img']\n",
    "        \n",
    "        # Get masks for this image\n",
    "        fused, masks = fuse_with_spatial_model(model, ct_img, mri_img)\n",
    "        \n",
    "        if masks is not None:\n",
    "            print(f\"Image {i+1} ({result['image_name']}):\")\n",
    "            \n",
    "            for mask_name, mask in masks.items():\n",
    "                mask_analysis[mask_name].append(mask)\n",
    "                ct_preference = mask.mean()\n",
    "                mri_preference = 1 - ct_preference\n",
    "                \n",
    "                print(f\"  {mask_name:3s}: CT={ct_preference:.3f}, MRI={mri_preference:.3f}\", end=\"\")\n",
    "                if ct_preference > 0.6:\n",
    "                    print(\" (Favors CT)\")\n",
    "                elif mri_preference > 0.6:\n",
    "                    print(\" (Favors MRI)\")\n",
    "                else:\n",
    "                    print(\" (Balanced)\")\n",
    "            \n",
    "            # Overall fusion preference\n",
    "            avg_ct_pref = np.mean([masks[name].mean() for name in masks.keys()])\n",
    "            fusion_preferences.append(avg_ct_pref)\n",
    "            print(f\"  Overall CT preference: {avg_ct_pref:.3f}\")\n",
    "            print()\n",
    "    \n",
    "    # Aggregate mask analysis\n",
    "    print(\"AGGREGATE MASK STATISTICS\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for mask_name in mask_analysis.keys():\n",
    "        if mask_analysis[mask_name]:\n",
    "            all_masks = np.array(mask_analysis[mask_name])\n",
    "            mean_mask = np.mean(all_masks, axis=0)\n",
    "            std_mask = np.std(all_masks, axis=0)\n",
    "            \n",
    "            overall_ct_pref = np.mean([mask.mean() for mask in mask_analysis[mask_name]])\n",
    "            spatial_variability = np.mean([mask.std() for mask in mask_analysis[mask_name]])\n",
    "            \n",
    "            print(f\"{mask_name} Band:\")\n",
    "            print(f\"  Average CT preference: {overall_ct_pref:.3f}\")\n",
    "            print(f\"  Spatial variability:   {spatial_variability:.3f}\")\n",
    "            print(f\"  Consistency across images: {1 - np.std([mask.mean() for mask in mask_analysis[mask_name]]):.3f}\")\n",
    "    \n",
    "    print(f\"\\nFUSION STRATEGY ANALYSIS\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    overall_ct_pref = np.mean(fusion_preferences)\n",
    "    consistency = 1 - np.std(fusion_preferences)\n",
    "    \n",
    "    print(f\"Average CT preference across all images: {overall_ct_pref:.3f}\")\n",
    "    print(f\"Strategy consistency: {consistency:.3f}\")\n",
    "    \n",
    "    if overall_ct_pref > 0.6:\n",
    "        strategy = \"CT-favoring\"\n",
    "    elif overall_ct_pref < 0.4:\n",
    "        strategy = \"MRI-favoring\"\n",
    "    else:\n",
    "        strategy = \"Balanced\"\n",
    "    \n",
    "    print(f\"Learned fusion strategy: {strategy}\")\n",
    "    \n",
    "    # Visualize mask statistics\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Mask preferences by frequency band\n",
    "    plt.subplot(2, 3, 1)\n",
    "    mask_names = list(mask_analysis.keys())\n",
    "    ct_preferences = [np.mean([mask.mean() for mask in mask_analysis[name]]) for name in mask_names]\n",
    "    \n",
    "    bars = plt.bar(range(len(mask_names)), ct_preferences, color=['purple', 'blue', 'green', 'red'])\n",
    "    plt.axhline(y=0.5, color='black', linestyle='--', alpha=0.7, label='Equal Preference')\n",
    "    plt.xlabel('Frequency Band')\n",
    "    plt.ylabel('Average CT Preference')\n",
    "    plt.title('Learned Fusion Preferences by Frequency')\n",
    "    plt.xticks(range(len(mask_names)), ['Low', 'LH', 'HL', 'HH'])\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (bar, val) in enumerate(zip(bars, ct_preferences)):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                f'{val:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    # Spatial variability\n",
    "    plt.subplot(2, 3, 2)\n",
    "    spatial_vars = [np.mean([mask.std() for mask in mask_analysis[name]]) for name in mask_names]\n",
    "    plt.bar(range(len(mask_names)), spatial_vars, color=['purple', 'blue', 'green', 'red'])\n",
    "    plt.xlabel('Frequency Band')\n",
    "    plt.ylabel('Average Spatial Variability')\n",
    "    plt.title('Spatial Adaptivity by Frequency')\n",
    "    plt.xticks(range(len(mask_names)), ['Low', 'LH', 'HL', 'HH'])\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Consistency across images\n",
    "    plt.subplot(2, 3, 3)\n",
    "    consistencies = [1 - np.std([mask.mean() for mask in mask_analysis[name]]) for name in mask_names]\n",
    "    plt.bar(range(len(mask_names)), consistencies, color=['purple', 'blue', 'green', 'red'])\n",
    "    plt.xlabel('Frequency Band')\n",
    "    plt.ylabel('Strategy Consistency')\n",
    "    plt.title('Fusion Strategy Consistency')\n",
    "    plt.xticks(range(len(mask_names)), ['Low', 'LH', 'HL', 'HH'])\n",
    "    plt.ylim(0, 1)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Average mask visualization\n",
    "    plt.subplot(2, 3, 4)\n",
    "    if mask_analysis['mL']:\n",
    "        avg_low_mask = np.mean(mask_analysis['mL'], axis=0)\n",
    "        plt.imshow(avg_low_mask, cmap='RdBu_r', vmin=0, vmax=1)\n",
    "        plt.title('Average Low-frequency Mask')\n",
    "        plt.colorbar()\n",
    "        plt.axis('off')\n",
    "    \n",
    "    # Mask correlation analysis\n",
    "    plt.subplot(2, 3, 5)\n",
    "    if len(mask_analysis['mL']) > 1:\n",
    "        # Calculate correlations between different frequency masks\n",
    "        mask_correlations = np.zeros((4, 4))\n",
    "        mask_names_short = ['L', 'LH', 'HL', 'HH']\n",
    "        \n",
    "        for i, name1 in enumerate(mask_analysis.keys()):\n",
    "            for j, name2 in enumerate(mask_analysis.keys()):\n",
    "                if mask_analysis[name1] and mask_analysis[name2]:\n",
    "                    correlations = []\n",
    "                    for k in range(len(mask_analysis[name1])):\n",
    "                        mask1 = mask_analysis[name1][k].flatten()\n",
    "                        mask2 = mask_analysis[name2][k].flatten()\n",
    "                        corr = np.corrcoef(mask1, mask2)[0, 1]\n",
    "                        if not np.isnan(corr):\n",
    "                            correlations.append(corr)\n",
    "                    mask_correlations[i, j] = np.mean(correlations) if correlations else 0\n",
    "        \n",
    "        im = plt.imshow(mask_correlations, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "        plt.title('Mask Correlation Matrix')\n",
    "        plt.xticks(range(4), mask_names_short)\n",
    "        plt.yticks(range(4), mask_names_short)\n",
    "        plt.colorbar(im)\n",
    "        \n",
    "        # Add correlation values\n",
    "        for i in range(4):\n",
    "            for j in range(4):\n",
    "                plt.text(j, i, f'{mask_correlations[i,j]:.2f}', ha='center', va='center')\n",
    "    \n",
    "    # Performance vs. adaptivity scatter\n",
    "    plt.subplot(2, 3, 6)\n",
    "    if len(comparison_results) > 1:\n",
    "        adaptivity_scores = []\n",
    "        performance_scores = []\n",
    "        \n",
    "        for result in comparison_results:\n",
    "            if 'Spatial-Adaptive Model' in result['methods']:\n",
    "                # Adaptivity: how much the model deviates from 0.5 (balanced)\n",
    "                ct_img, mri_img = result['ct_img'], result['mri_img']\n",
    "                fused, masks = fuse_with_spatial_model(model, ct_img, mri_img)\n",
    "                \n",
    "                if masks:\n",
    "                    avg_deviation = np.mean([np.mean(np.abs(mask - 0.5)) for mask in masks.values()])\n",
    "                    adaptivity_scores.append(avg_deviation)\n",
    "                    \n",
    "                    # Performance: SSIM score\n",
    "                    performance_scores.append(result['methods']['Spatial-Adaptive Model']['SSIM_Avg'])\n",
    "        \n",
    "        if adaptivity_scores and performance_scores:\n",
    "            plt.scatter(adaptivity_scores, performance_scores, alpha=0.7, s=100)\n",
    "            plt.xlabel('Spatial Adaptivity\\n(Deviation from Balanced)')\n",
    "            plt.ylabel('Fusion Quality (SSIM)')\n",
    "            plt.title('Adaptivity vs. Performance')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Add trend line\n",
    "            if len(adaptivity_scores) > 2:\n",
    "                z = np.polyfit(adaptivity_scores, performance_scores, 1)\n",
    "                p = np.poly1d(z)\n",
    "                plt.plot(adaptivity_scores, p(adaptivity_scores), \"r--\", alpha=0.8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\n\" + \"=\" * 80)\n",
    "    print(\"ANALYSIS COMPLETE\")\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc834e43",
   "metadata": {},
   "source": [
    "## 10. Summary and Conclusions\n",
    "\n",
    "Summarize the performance and characteristics of the spatial-adaptive wavelet fusion model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7b6f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model is not None and 'comparison_results' in locals():\n",
    "    print(\"=\" * 90)\n",
    "    print(\"SPATIAL-ADAPTIVE WAVELET FUSION MODEL - FINAL SUMMARY\")\n",
    "    print(\"=\" * 90)\n",
    "    \n",
    "    print(f\"\\nðŸ”¬ MODEL CHARACTERISTICS:\")\n",
    "    print(f\"   â€¢ Architecture: Spatial-Adaptive Wavelet Fusion Network\")\n",
    "    print(f\"   â€¢ Frequency Bands: Low, LH, HL, HH (Haar wavelets)\")\n",
    "    print(f\"   â€¢ Spatial Masks: CNN-generated adaptive fusion weights\")\n",
    "    print(f\"   â€¢ Training: Enhanced loss (L1 + SSIM + Gradient)\")\n",
    "    \n",
    "    if 'Spatial-Adaptive Model' in aggregate_stats:\n",
    "        stats = aggregate_stats['Spatial-Adaptive Model']\n",
    "        \n",
    "        print(f\"\\nðŸ“Š PERFORMANCE METRICS:\")\n",
    "        print(f\"   â€¢ SSIM:              {stats['SSIM_Avg']['mean']:.3f} Â± {stats['SSIM_Avg']['std']:.3f}\")\n",
    "        print(f\"   â€¢ PSNR:              {stats['PSNR_Avg']['mean']:.1f} Â± {stats['PSNR_Avg']['std']:.1f} dB\")\n",
    "        print(f\"   â€¢ Edge Preservation: {stats['Edge_Preservation']['mean']:.3f} Â± {stats['Edge_Preservation']['std']:.3f}\")\n",
    "        print(f\"   â€¢ Information Content: {stats['Entropy']['mean']:.2f} Â± {stats['Entropy']['std']:.2f} bits\")\n",
    "        print(f\"   â€¢ Mutual Information: {stats['MI_Avg']['mean']:.3f} Â± {stats['MI_Avg']['std']:.3f} bits\")\n",
    "        \n",
    "        # Quality assessment\n",
    "        avg_ssim = stats['SSIM_Avg']['mean']\n",
    "        avg_psnr = stats['PSNR_Avg']['mean']\n",
    "        edge_pres = stats['Edge_Preservation']['mean']\n",
    "        \n",
    "        quality_indicators = []\n",
    "        if avg_ssim >= 0.8: quality_indicators.append(\"Excellent structure preservation\")\n",
    "        elif avg_ssim >= 0.7: quality_indicators.append(\"Good structure preservation\")\n",
    "        else: quality_indicators.append(\"Fair structure preservation\")\n",
    "        \n",
    "        if avg_psnr >= 25: quality_indicators.append(\"High signal quality\")\n",
    "        elif avg_psnr >= 20: quality_indicators.append(\"Good signal quality\")\n",
    "        else: quality_indicators.append(\"Moderate signal quality\")\n",
    "        \n",
    "        if edge_pres >= 0.9: quality_indicators.append(\"Excellent edge preservation\")\n",
    "        elif edge_pres >= 0.8: quality_indicators.append(\"Good edge preservation\")\n",
    "        else: quality_indicators.append(\"Moderate edge preservation\")\n",
    "        \n",
    "        print(f\"\\nâœ… QUALITY ASSESSMENT:\")\n",
    "        for indicator in quality_indicators:\n",
    "            print(f\"   â€¢ {indicator}\")\n",
    "        \n",
    "        # Ranking analysis\n",
    "        rankings = {}\n",
    "        for metric in metrics_names:\n",
    "            sorted_methods = sorted(method_names, \n",
    "                                   key=lambda x: aggregate_stats[x][metric]['mean'], \n",
    "                                   reverse=True)\n",
    "            if 'Spatial-Adaptive Model' in sorted_methods:\n",
    "                rank = sorted_methods.index('Spatial-Adaptive Model') + 1\n",
    "                rankings[metric] = rank\n",
    "        \n",
    "        print(f\"\\nðŸ† PERFORMANCE RANKING:\")\n",
    "        for metric, rank in rankings.items():\n",
    "            print(f\"   â€¢ {metric:20s}: #{rank}/{len(method_names)}\")\n",
    "        \n",
    "        # Best improvements\n",
    "        print(f\"\\nðŸ“ˆ IMPROVEMENTS OVER BASELINES:\")\n",
    "        best_improvements = []\n",
    "        for baseline in ['Average', 'Maximum', 'Weighted (0.6)']:\n",
    "            if baseline in aggregate_stats:\n",
    "                ssim_imp = ((stats['SSIM_Avg']['mean'] - aggregate_stats[baseline]['SSIM_Avg']['mean']) / \n",
    "                           aggregate_stats[baseline]['SSIM_Avg']['mean'] * 100)\n",
    "                psnr_imp = stats['PSNR_Avg']['mean'] - aggregate_stats[baseline]['PSNR_Avg']['mean']\n",
    "                edge_imp = ((stats['Edge_Preservation']['mean'] - aggregate_stats[baseline]['Edge_Preservation']['mean']) /\n",
    "                           aggregate_stats[baseline]['Edge_Preservation']['mean'] * 100)\n",
    "                \n",
    "                if ssim_imp > 0:\n",
    "                    best_improvements.append(f\"SSIM vs {baseline}: +{ssim_imp:.1f}%\")\n",
    "                if psnr_imp > 0:\n",
    "                    best_improvements.append(f\"PSNR vs {baseline}: +{psnr_imp:.1f}dB\")\n",
    "                if edge_imp > 0:\n",
    "                    best_improvements.append(f\"Edge vs {baseline}: +{edge_imp:.1f}%\")\n",
    "        \n",
    "        for improvement in best_improvements[:5]:  # Show top 5 improvements\n",
    "            print(f\"   â€¢ {improvement}\")\n",
    "    \n",
    "    # Fusion strategy analysis\n",
    "    if fusion_preferences:\n",
    "        print(f\"\\nðŸ§  LEARNED FUSION STRATEGY:\")\n",
    "        overall_ct_pref = np.mean(fusion_preferences)\n",
    "        \n",
    "        if overall_ct_pref > 0.6:\n",
    "            strategy_desc = \"CT-favoring (emphasizes anatomical structure)\"\n",
    "        elif overall_ct_pref < 0.4:\n",
    "            strategy_desc = \"MRI-favoring (emphasizes soft tissue contrast)\"\n",
    "        else:\n",
    "            strategy_desc = \"Balanced (adaptive to local content)\"\n",
    "        \n",
    "        print(f\"   â€¢ Overall strategy: {strategy_desc}\")\n",
    "        print(f\"   â€¢ CT preference: {overall_ct_pref:.1%}\")\n",
    "        print(f\"   â€¢ MRI preference: {1-overall_ct_pref:.1%}\")\n",
    "        print(f\"   â€¢ Consistency: {1 - np.std(fusion_preferences):.3f}\")\n",
    "        \n",
    "        # Frequency-specific insights\n",
    "        if mask_analysis['mL']:\n",
    "            freq_preferences = {\n",
    "                'Low': np.mean([mask.mean() for mask in mask_analysis['mL']]),\n",
    "                'LH': np.mean([mask.mean() for mask in mask_analysis['mLH']]),\n",
    "                'HL': np.mean([mask.mean() for mask in mask_analysis['mHL']]),\n",
    "                'HH': np.mean([mask.mean() for mask in mask_analysis['mHH']])\n",
    "            }\n",
    "            \n",
    "            print(f\"\\n   Frequency-specific preferences:\")\n",
    "            for freq, pref in freq_preferences.items():\n",
    "                if pref > 0.6:\n",
    "                    desc = \"Favors CT\"\n",
    "                elif pref < 0.4:\n",
    "                    desc = \"Favors MRI\"\n",
    "                else:\n",
    "                    desc = \"Balanced\"\n",
    "                print(f\"   â€¢ {freq:3s} frequency: {pref:.3f} ({desc})\")\n",
    "    \n",
    "    # Model advantages\n",
    "    print(f\"\\nðŸŒŸ KEY ADVANTAGES:\")\n",
    "    print(f\"   â€¢ Spatial adaptivity: Location-aware fusion decisions\")\n",
    "    print(f\"   â€¢ Multi-frequency: Separate strategies for different details\")\n",
    "    print(f\"   â€¢ End-to-end learning: Optimized for fusion quality\")\n",
    "    print(f\"   â€¢ Edge preservation: Maintains important structural details\")\n",
    "    print(f\"   â€¢ Automated: No manual parameter tuning required\")\n",
    "    \n",
    "    # Recommendations\n",
    "    print(f\"\\nðŸ’¡ RECOMMENDATIONS:\")\n",
    "    if avg_ssim >= 0.75 and avg_psnr >= 20:\n",
    "        print(f\"   â€¢ Model performance is GOOD - ready for practical use\")\n",
    "        print(f\"   â€¢ Consider testing on additional diverse datasets\")\n",
    "    elif avg_ssim >= 0.65:\n",
    "        print(f\"   â€¢ Model performance is FAIR - may benefit from:\")\n",
    "        print(f\"     - More training epochs\")\n",
    "        print(f\"     - Larger training dataset\")\n",
    "        print(f\"     - Hyperparameter tuning\")\n",
    "    else:\n",
    "        print(f\"   â€¢ Model needs improvement - consider:\")\n",
    "        print(f\"     - Architecture modifications\")\n",
    "        print(f\"     - Different loss function weights\")\n",
    "        print(f\"     - More diverse training data\")\n",
    "    \n",
    "    print(f\"\\n\" + \"=\" * 90)\n",
    "    print(\"TESTING AND EVALUATION COMPLETE\")\n",
    "    print(\"=\" * 90)\n",
    "\n",
    "else:\n",
    "    print(\"âŒ Model evaluation could not be completed.\")\n",
    "    print(\"Please ensure the model is trained and checkpoint is available.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
