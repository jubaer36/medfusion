{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "enhanced_fusion",
   "metadata": {},
   "source": [
    "# Enhanced Trainable Wavelet-based CT–MRI Fusion\n",
    "**Improved model with overfitting prevention techniques**\n",
    "\n",
    "This enhanced notebook includes:\n",
    "- **Regularization techniques**: Dropout, weight decay, batch normalization\n",
    "- **Early stopping** with patience mechanism\n",
    "- **Learning rate scheduling** with ReduceLROnPlateau\n",
    "- **Data augmentation** for better generalization\n",
    "- **Cross-validation** for robust evaluation\n",
    "- **Improved architecture** with residual connections\n",
    "- **Better loss balancing** with adaptive weights\n",
    "- **Model ensemble** capabilities\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports",
   "metadata": {},
   "source": [
    "## 1) Enhanced Imports & Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports_code",
   "metadata": {},
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from typing import Tuple, List, Dict, Optional\n",
    "from dataclasses import dataclass, asdict\n",
    "from collections import defaultdict\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingLR\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torchvision import models, transforms\n",
    "from pytorch_wavelets import DWTForward, DWTInverse\n",
    "\n",
    "# Enhanced reproducibility\n",
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}  {

   "cell_type": "markdown",
   "id": "config",
   "metadata": {},
   "source": [
    "## 2) Enhanced Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class EnhancedConfig:\n",
    "    # Data paths\n",
    "    ct_dir: str = 'Harvard-Medical-Image-Fusion-Datasets/MyDatasets/CT-MRI/train/CT'\n",
    "    mri_dir: str = 'Harvard-Medical-Image-Fusion-Datasets/MyDatasets/CT-MRI/train/MRI'\n",
    "    save_dir: str = 'checkpoints_enhanced'\n",
    "    \n",
    "    # Data preprocessing\n",
    "    resize: Optional[Tuple[int, int]] = (256, 256)  # Standardize input size\n",
    "    normalize: bool = True\n",
    "    augment_data: bool = True\n",
    "    \n",
    "    # Training parameters\n",
    "    batch_size: int = 8  # Reduced for better generalization\n",
    "    epochs: int = 100\n",
    "    lr: float = 1e-4  # Lower learning rate\n",
    "    weight_decay: float = 1e-4  # L2 regularization\n",
    "    \n",
    "    # Validation and early stopping\n",
    "    val_split: float = 0.2  # Larger validation set\n",
    "    early_stopping_patience: int = 15\n",
    "    min_delta: float = 1e-4\n",
    "    \n",
    "    # Cross-validation\n",
    "    use_kfold: bool = False\n",
    "    k_folds: int = 5\n",
    "    \n",
    "    # Model architecture\n",
    "    wave: str = 'db4'  # Better wavelet than Haar\n",
    "    dwt_levels: int = 2  # Multi-level DWT\n",
    "    use_residual: bool = True\n",
    "    dropout_rate: float = 0.1\n",
    "    use_batch_norm: bool = True\n",
    "    \n",
    "    # Loss weights with adaptive balancing\n",
    "    w_ssim: float = 1.0\n",
    "    w_grad: float = 1.0\n",
    "    w_perc: float = 0.1\n",
    "    w_tv: float = 0.01  # Total variation loss\n",
    "    adaptive_weights: bool = True\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    use_scheduler: bool = True\n",
    "    scheduler_type: str = 'plateau'  # 'plateau' or 'cosine'\n",
    "    lr_patience: int = 8\n",
    "    lr_factor: float = 0.5\n",
    "    \n",
    "    # Ensemble\n",
    "    ensemble_size: int = 3\n",
    "    \n",
    "    def save(self, path: str):\n",
    "        with open(path, 'w') as f:\n",
    "            json.dump(asdict(self), f, indent=2)\n",
    "    \n",
    "    @classmethod\n",
    "    def load(cls, path: str):\n",
    "        with open(path, 'r') as f:\n",
    "            return cls(**json.load(f))\n",
    "\n",
    "cfg = EnhancedConfig()\n",
    "print(\"Enhanced Configuration:\")\n",
    "for key, value in asdict(cfg).items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dataset",
   "metadata": {},
   "source": [
    "## 3) Enhanced Dataset with Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dataset_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedMedicalFusionDataset(Dataset):\n",
    "    \"\"\"Enhanced dataset with data augmentation and normalization.\"\"\"\n",
    "    \n",
    "    def __init__(self, root_ct: str, root_mri: str, \n",
    "                 resize: Optional[Tuple[int, int]] = None,\n",
    "                 augment: bool = False,\n",
    "                 normalize: bool = True,\n",
    "                 file_exts=(\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tif\", \".tiff\")):\n",
    "        self.root_ct = root_ct\n",
    "        self.root_mri = root_mri\n",
    "        self.resize = resize\n",
    "        self.augment = augment\n",
    "        self.normalize = normalize\n",
    "        \n",
    "        # Index directories\n",
    "        def index_dir(root):\n",
    "            paths = []\n",
    "            for ext in file_exts:\n",
    "                paths.extend(glob.glob(os.path.join(root, f\"**/*{ext}\"), recursive=True))\n",
    "            base = {os.path.splitext(os.path.relpath(p, root))[0].replace('\\\\', '/'): p for p in paths}\n",
    "            return base\n",
    "        \n",
    "        base_ct = index_dir(root_ct)\n",
    "        base_mr = index_dir(root_mri)\n",
    "        self.keys = sorted(list(set(base_ct.keys()) & set(base_mr.keys())))\n",
    "        \n",
    "        if not self.keys:\n",
    "            raise RuntimeError(\"No paired files found. Ensure matching filenames between CT and MRI.\")\n",
    "        \n",
    "        self.base_ct = base_ct\n",
    "        self.base_mr = base_mr\n",
    "        \n",
    "        # Compute dataset statistics for normalization\n",
    "        if self.normalize:\n",
    "            self._compute_stats()\n",
    "    \n",
    "    def _compute_stats(self):\n",
    "        \"\"\"Compute mean and std for normalization.\"\"\"\n",
    "        print(\"Computing dataset statistics...\")\n",
    "        ct_values, mr_values = [], []\n",
    "        \n",
    "        # Sample subset for efficiency\n",
    "        sample_keys = self.keys[::max(1, len(self.keys) // 50)]\n",
    "        \n",
    "        for key in sample_keys:\n",
    "            ct = cv2.imread(self.base_ct[key], cv2.IMREAD_GRAYSCALE)\n",
    "            mr = cv2.imread(self.base_mr[key], cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            if ct is not None and mr is not None:\n",
    "                ct = ct.astype(np.float32) / 255.0\n",
    "                mr = mr.astype(np.float32) / 255.0\n",
    "                ct_values.extend(ct.flatten())\n",
    "                mr_values.extend(mr.flatten())\n",
    "        \n",
    "        self.ct_mean, self.ct_std = np.mean(ct_values), np.std(ct_values)\n",
    "        self.mr_mean, self.mr_std = np.mean(mr_values), np.std(mr_values)\n",
    "        \n",
    "        print(f\"CT stats: mean={self.ct_mean:.4f}, std={self.ct_std:.4f}\")\n",
    "        print(f\"MR stats: mean={self.mr_mean:.4f}, std={self.mr_std:.4f}\")\n",
    "    \n",
    "    def _augment_pair(self, ct: np.ndarray, mr: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Apply consistent augmentation to both images.\"\"\"\n",
    "        if not self.augment:\n",
    "            return ct, mr\n",
    "        \n",
    "        # Random horizontal flip\n",
    "        if random.random() > 0.5:\n",
    "            ct = cv2.flip(ct, 1)\n",
    "            mr = cv2.flip(mr, 1)\n",
    "        \n",
    "        # Random rotation (-10 to 10 degrees)\n",
    "        if random.random() > 0.5:\n",
    "            angle = random.uniform(-10, 10)\n",
    "            h, w = ct.shape\n",
    "            center = (w // 2, h // 2)\n",
    "            M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "            ct = cv2.warpAffine(ct, M, (w, h), borderMode=cv2.BORDER_REFLECT)\n",
    "            mr = cv2.warpAffine(mr, M, (w, h), borderMode=cv2.BORDER_REFLECT)\n",
    "        \n",
    "        # Random brightness adjustment (±10%)\n",
    "        if random.random() > 0.5:\n",
    "            brightness_factor = random.uniform(0.9, 1.1)\n",
    "            ct = np.clip(ct * brightness_factor, 0, 1)\n",
    "            mr = np.clip(mr * brightness_factor, 0, 1)\n",
    "        \n",
    "        return ct, mr\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        key = self.keys[idx]\n",
    "        p_ct = self.base_ct[key]\n",
    "        p_mr = self.base_mr[key]\n",
    "        \n",
    "        ct = cv2.imread(p_ct, cv2.IMREAD_GRAYSCALE)\n",
    "        mr = cv2.imread(p_mr, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        if ct is None or mr is None:\n",
    "            raise FileNotFoundError(f\"Could not load: {p_ct if ct is None else p_mr}\")\n",
    "        \n",
    "        # Resize if specified\n",
    "        if self.resize is not None:\n",
    "            H, W = self.resize\n",
    "            ct = cv2.resize(ct, (W, H), interpolation=cv2.INTER_AREA)\n",
    "            mr = cv2.resize(mr, (W, H), interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        # Convert to float and normalize to [0, 1]\n",
    "        ct = ct.astype(np.float32) / 255.0\n",
    "        mr = mr.astype(np.float32) / 255.0\n",
    "        \n",
    "        # Apply augmentation\n",
    "        ct, mr = self._augment_pair(ct, mr)\n",
    "        \n",
    "        # Normalize using dataset statistics\n",
    "        if self.normalize:\n",
    "            ct = (ct - self.ct_mean) / (self.ct_std + 1e-8)\n",
    "            mr = (mr - self.mr_mean) / (self.mr_std + 1e-8)\n",
    "        \n",
    "        # Convert to tensors\n",
    "        ct_t = torch.from_numpy(ct)[None, ...]  # (1, H, W)\n",
    "        mr_t = torch.from_numpy(mr)[None, ...]\n",
    "        \n",
    "        return ct_t, mr_t, key"
   ]
  }  {

   "cell_type": "markdown",
   "id": "losses",
   "metadata": {},
   "source": [
    "## 4) Enhanced Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "losses_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedSSIM(nn.Module):\n",
    "    \"\"\"Enhanced SSIM with multiple window sizes.\"\"\"\n",
    "    \n",
    "    def __init__(self, window_sizes=[11, 9, 7], C1=0.01**2, C2=0.03**2):\n",
    "        super().__init__()\n",
    "        self.window_sizes = window_sizes\n",
    "        self.C1 = C1\n",
    "        self.C2 = C2\n",
    "        \n",
    "        # Create Gaussian windows for different sizes\n",
    "        self.windows = nn.ModuleDict()\n",
    "        for ws in window_sizes:\n",
    "            gauss = cv2.getGaussianKernel(ws, ws/6)\n",
    "            gauss = gauss @ gauss.T\n",
    "            w = torch.from_numpy(gauss.astype(np.float32))[None, None]\n",
    "            self.register_buffer(f'window_{ws}', w)\n",
    "    \n",
    "    def _compute_ssim(self, x, y, window_size):\n",
    "        window = getattr(self, f'window_{window_size}').to(x.device)\n",
    "        pad = window_size // 2\n",
    "        \n",
    "        mu_x = F.conv2d(x, window, padding=pad, groups=x.size(1))\n",
    "        mu_y = F.conv2d(y, window, padding=pad, groups=y.size(1))\n",
    "        mu_x2, mu_y2, mu_xy = mu_x*mu_x, mu_y*mu_y, mu_x*mu_y\n",
    "        \n",
    "        sigma_x2 = F.conv2d(x*x, window, padding=pad, groups=x.size(1)) - mu_x2\n",
    "        sigma_y2 = F.conv2d(y*y, window, padding=pad, groups=y.size(1)) - mu_y2\n",
    "        sigma_xy = F.conv2d(x*y, window, padding=pad, groups=x.size(1)) - mu_xy\n",
    "        \n",
    "        ssim = ((2*mu_xy + self.C1)*(2*sigma_xy + self.C2)) / \\\n",
    "               ((mu_x2 + mu_y2 + self.C1)*(sigma_x2 + sigma_y2 + self.C2) + 1e-8)\n",
    "        \n",
    "        return ssim.mean()\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        # Multi-scale SSIM\n",
    "        ssim_values = []\n",
    "        for ws in self.window_sizes:\n",
    "            ssim_values.append(self._compute_ssim(x, y, ws))\n",
    "        return sum(ssim_values) / len(ssim_values)\n",
    "\n",
    "\n",
    "class TotalVariationLoss(nn.Module):\n",
    "    \"\"\"Total Variation loss for smoothness regularization.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Compute gradients\n",
    "        diff_i = torch.abs(x[:, :, 1:, :] - x[:, :, :-1, :])\n",
    "        diff_j = torch.abs(x[:, :, :, 1:] - x[:, :, :, :-1])\n",
    "        return diff_i.mean() + diff_j.mean()\n",
    "\n",
    "\n",
    "class EnhancedGradientLoss(nn.Module):\n",
    "    \"\"\"Enhanced gradient loss with multiple operators.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Sobel operators\n",
    "        kx = np.array([[1, 0, -1], [2, 0, -2], [1, 0, -1]], dtype=np.float32)\n",
    "        ky = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]], dtype=np.float32)\n",
    "        self.register_buffer('kx', torch.from_numpy(kx)[None, None])\n",
    "        self.register_buffer('ky', torch.from_numpy(ky)[None, None])\n",
    "        \n",
    "        # Laplacian operator\n",
    "        laplacian = np.array([[0, -1, 0], [-1, 4, -1], [0, -1, 0]], dtype=np.float32)\n",
    "        self.register_buffer('laplacian', torch.from_numpy(laplacian)[None, None])\n",
    "    \n",
    "    def _compute_gradients(self, img):\n",
    "        gx = F.conv2d(img, self.kx, padding=1)\n",
    "        gy = F.conv2d(img, self.ky, padding=1)\n",
    "        grad_mag = torch.sqrt(gx*gx + gy*gy + 1e-8)\n",
    "        \n",
    "        # Also compute Laplacian for edge detection\n",
    "        lapl = torch.abs(F.conv2d(img, self.laplacian, padding=1))\n",
    "        \n",
    "        return grad_mag, lapl\n",
    "    \n",
    "    def forward(self, fused, ct, mr):\n",
    "        gF, lF = self._compute_gradients(fused)\n",
    "        gC, lC = self._compute_gradients(ct)\n",
    "        gM, lM = self._compute_gradients(mr)\n",
    "        \n",
    "        # Target is maximum gradient/edge information\n",
    "        gT = torch.max(gC, gM)\n",
    "        lT = torch.max(lC, lM)\n",
    "        \n",
    "        grad_loss = F.l1_loss(gF, gT)\n",
    "        lapl_loss = F.l1_loss(lF, lT)\n",
    "        \n",
    "        return 0.7 * grad_loss + 0.3 * lapl_loss\n",
    "\n",
    "\n",
    "class AdaptiveFusionLoss(nn.Module):\n",
    "    \"\"\"Adaptive fusion loss with dynamic weight balancing.\"\"\"\n",
    "    \n",
    "    def __init__(self, device, w_ssim=1.0, w_grad=1.0, w_perc=0.1, w_tv=0.01, adaptive=True):\n",
    "        super().__init__()\n",
    "        self.ssim = EnhancedSSIM()\n",
    "        self.grad = EnhancedGradientLoss()\n",
    "        self.tv = TotalVariationLoss()\n",
    "        \n",
    "        # VGG perceptual loss\n",
    "        vgg = models.vgg19(weights='VGG19_Weights.IMAGENET1K_V1').features\n",
    "        self.vgg_slice1 = nn.Sequential(*[vgg[i] for i in range(4)])   # relu1_2\n",
    "        self.vgg_slice2 = nn.Sequential(*[vgg[i] for i in range(4, 9)]) # relu2_2\n",
    "        self.vgg_slice3 = nn.Sequential(*[vgg[i] for i in range(9, 18)]) # relu3_4\n",
    "        \n",
    "        for p in self.vgg_slice1.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.vgg_slice2.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.vgg_slice3.parameters():\n",
    "            p.requires_grad = False\n",
    "        \n",
    "        self.to(device)\n",
    "        \n",
    "        # Loss weights\n",
    "        self.w_ssim = w_ssim\n",
    "        self.w_grad = w_grad\n",
    "        self.w_perc = w_perc\n",
    "        self.w_tv = w_tv\n",
    "        self.adaptive = adaptive\n",
    "        \n",
    "        # For adaptive weighting\n",
    "        self.loss_history = defaultdict(list)\n",
    "        self.update_count = 0\n",
    "    \n",
    "    def _extract_vgg_features(self, x):\n",
    "        # Convert grayscale to RGB and normalize for VGG\n",
    "        x3 = x.repeat(1, 3, 1, 1)\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406], device=x.device)[None, :, None, None]\n",
    "        std = torch.tensor([0.229, 0.224, 0.225], device=x.device)[None, :, None, None]\n",
    "        x3 = (x3 - mean) / std\n",
    "        \n",
    "        f1 = self.vgg_slice1(x3)\n",
    "        f2 = self.vgg_slice2(f1)\n",
    "        f3 = self.vgg_slice3(f2)\n",
    "        \n",
    "        return f1, f2, f3\n",
    "    \n",
    "    def _perceptual_loss(self, fused, ct, mr):\n",
    "        fF1, fF2, fF3 = self._extract_vgg_features(fused)\n",
    "        cF1, cF2, cF3 = self._extract_vgg_features(ct)\n",
    "        mF1, mF2, mF3 = self._extract_vgg_features(mr)\n",
    "        \n",
    "        loss1 = 0.5 * (F.l1_loss(fF1, cF1) + F.l1_loss(fF1, mF1))\n",
    "        loss2 = 0.5 * (F.l1_loss(fF2, cF2) + F.l1_loss(fF2, mF2))\n",
    "        loss3 = 0.5 * (F.l1_loss(fF3, cF3) + F.l1_loss(fF3, mF3))\n",
    "        \n",
    "        return 0.2 * loss1 + 0.3 * loss2 + 0.5 * loss3\n",
    "    \n",
    "    def _update_adaptive_weights(self, losses):\n",
    "        \"\"\"Update loss weights based on relative magnitudes.\"\"\"\n",
    "        if not self.adaptive:\n",
    "            return\n",
    "        \n",
    "        self.update_count += 1\n",
    "        \n",
    "        # Store loss history\n",
    "        for key, value in losses.items():\n",
    "            self.loss_history[key].append(value)\n",
    "            if len(self.loss_history[key]) > 100:  # Keep only recent history\n",
    "                self.loss_history[key].pop(0)\n",
    "        \n",
    "        # Update weights every 50 iterations\n",
    "        if self.update_count % 50 == 0 and len(self.loss_history['ssim']) > 10:\n",
    "            # Compute relative loss magnitudes\n",
    "            avg_losses = {k: np.mean(v[-10:]) for k, v in self.loss_history.items()}\n",
    "            total_loss = sum(avg_losses.values())\n",
    "            \n",
    "            # Adjust weights inversely proportional to loss magnitude\n",
    "            if total_loss > 0:\n",
    "                self.w_ssim = min(2.0, max(0.1, 1.0 / (avg_losses['ssim'] / total_loss + 1e-8)))\n",
    "                self.w_grad = min(2.0, max(0.1, 1.0 / (avg_losses['grad'] / total_loss + 1e-8)))\n",
    "                self.w_perc = min(0.5, max(0.01, 0.1 / (avg_losses['perc'] / total_loss + 1e-8)))\n",
    "    \n",
    "    def forward(self, fused, ct, mr):\n",
    "        # Compute individual losses\n",
    "        l_ssim_ct = 1.0 - self.ssim(fused, ct)\n",
    "        l_ssim_mr = 1.0 - self.ssim(fused, mr)\n",
    "        l_ssim = 0.5 * (l_ssim_ct + l_ssim_mr)\n",
    "        \n",
    "        l_grad = self.grad(fused, ct, mr)\n",
    "        l_perc = self._perceptual_loss(fused, ct, mr)\n",
    "        l_tv = self.tv(fused)\n",
    "        \n",
    "        # Store individual loss values\n",
    "        losses = {\n",
    "            'ssim': l_ssim.item(),\n",
    "            'grad': l_grad.item(),\n",
    "            'perc': l_perc.item(),\n",
    "            'tv': l_tv.item()\n",
    "        }\n",
    "        \n",
    "        # Update adaptive weights\n",
    "        self._update_adaptive_weights(losses)\n",
    "        \n",
    "        # Compute total loss\n",
    "        total = (self.w_ssim * l_ssim + \n",
    "                self.w_grad * l_grad + \n",
    "                self.w_perc * l_perc + \n",
    "                self.w_tv * l_tv)\n",
    "        \n",
    "        # Add current weights to losses dict\n",
    "        losses.update({\n",
    "            'w_ssim': self.w_ssim,\n",
    "            'w_grad': self.w_grad,\n",
    "            'w_perc': self.w_perc,\n",
    "            'w_tv': self.w_tv\n",
    "        })\n",
    "        \n",
    "        return total, losses"
   ]
  }  {

   "cell_type": "markdown",
   "id": "model",
   "metadata": {},
   "source": [
    "## 5) Enhanced Wavelet Fusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"Residual block for feature refinement.\"\"\"\n",
    "    \n",
    "    def __init__(self, channels, dropout_rate=0.1, use_batch_norm=True):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, channels, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(channels, channels, 3, padding=1)\n",
    "        \n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        if use_batch_norm:\n",
    "            self.bn1 = nn.BatchNorm2d(channels)\n",
    "            self.bn2 = nn.BatchNorm2d(channels)\n",
    "        \n",
    "        self.dropout = nn.Dropout2d(dropout_rate)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        if self.use_batch_norm:\n",
    "            out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        if self.use_batch_norm:\n",
    "            out = self.bn2(out)\n",
    "        \n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "class AttentionModule(nn.Module):\n",
    "    \"\"\"Channel attention module for adaptive feature weighting.\"\"\"\n",
    "    \n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels // reduction, 1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channels // reduction, channels, 1, bias=False)\n",
    "        )\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc(self.avg_pool(x))\n",
    "        max_out = self.fc(self.max_pool(x))\n",
    "        attention = self.sigmoid(avg_out + max_out)\n",
    "        return x * attention\n",
    "\n",
    "\n",
    "class EnhancedWaveletFusionNet(nn.Module):\n",
    "    \"\"\"Enhanced wavelet fusion network with regularization and attention.\"\"\"\n",
    "    \n",
    "    def __init__(self, wave='db4', dwt_levels=2, use_residual=True, \n",
    "                 dropout_rate=0.1, use_batch_norm=True):\n",
    "        super().__init__()\n",
    "        self.dwt_levels = dwt_levels\n",
    "        self.use_residual = use_residual\n",
    "        \n",
    "        # Wavelet transforms\n",
    "        self.dwt = DWTForward(J=dwt_levels, wave=wave)\n",
    "        self.idwt = DWTInverse(wave=wave)\n",
    "        \n",
    "        # Learnable fusion parameters for each level and subband\n",
    "        self.fusion_params = nn.ParameterDict()\n",
    "        \n",
    "        # Low-frequency fusion parameters\n",
    "        self.fusion_params['low'] = nn.Parameter(torch.zeros(1))\n",
    "        \n",
    "        # High-frequency fusion parameters for each level\n",
    "        for level in range(dwt_levels):\n",
    "            for subband in ['lh', 'hl', 'hh']:\n",
    "                param_name = f'high_{level}_{subband}'\n",
    "                self.fusion_params[param_name] = nn.Parameter(torch.zeros(1))\n",
    "        \n",
    "        # Feature refinement modules\n",
    "        if use_residual:\n",
    "            self.low_refine = ResidualBlock(1, dropout_rate, use_batch_norm)\n",
    "            self.high_refine = nn.ModuleDict()\n",
    "            for level in range(dwt_levels):\n",
    "                self.high_refine[f'level_{level}'] = ResidualBlock(3, dropout_rate, use_batch_norm)\n",
    "        \n",
    "        # Attention modules\n",
    "        self.low_attention = AttentionModule(1)\n",
    "        self.high_attention = nn.ModuleDict()\n",
    "        for level in range(dwt_levels):\n",
    "            self.high_attention[f'level_{level}'] = AttentionModule(3)\n",
    "        \n",
    "        # Final refinement\n",
    "        self.final_refine = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, padding=1),\n",
    "            nn.BatchNorm2d(16) if use_batch_norm else nn.Identity(),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(dropout_rate),\n",
    "            nn.Conv2d(16, 8, 3, padding=1),\n",
    "            nn.BatchNorm2d(8) if use_batch_norm else nn.Identity(),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(8, 1, 3, padding=1),\n",
    "            nn.Tanh()  # Ensure output is in reasonable range\n",
    "        )\n",
    "        \n",
    "        # Initialize parameters\n",
    "        self._initialize_parameters()\n",
    "    \n",
    "    def _initialize_parameters(self):\n",
    "        \"\"\"Initialize fusion parameters and network weights.\"\"\"\n",
    "        # Initialize fusion parameters to 0.5 (equal weighting)\n",
    "        for param in self.fusion_params.values():\n",
    "            nn.init.constant_(param, 0.0)  # sigmoid(0) = 0.5\n",
    "        \n",
    "        # Initialize conv layers\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def get_fusion_weights(self):\n",
    "        \"\"\"Get current fusion weights as a dictionary.\"\"\"\n",
    "        weights = {}\n",
    "        for name, param in self.fusion_params.items():\n",
    "            weights[name] = torch.sigmoid(param).item()\n",
    "        return weights\n",
    "    \n",
    "    def forward(self, ct, mr):\n",
    "        # Multi-level DWT\n",
    "        ct_low, ct_highs = self.dwt(ct)\n",
    "        mr_low, mr_highs = self.dwt(mr)\n",
    "        \n",
    "        # Fuse low-frequency components\n",
    "        alpha_low = torch.sigmoid(self.fusion_params['low'])\n",
    "        fused_low = alpha_low * ct_low + (1.0 - alpha_low) * mr_low\n",
    "        \n",
    "        # Apply attention and refinement to low-frequency\n",
    "        fused_low = self.low_attention(fused_low)\n",
    "        if self.use_residual:\n",
    "            fused_low = self.low_refine(fused_low)\n",
    "        \n",
    "        # Fuse high-frequency components for each level\n",
    "        fused_highs = []\n",
    "        for level in range(self.dwt_levels):\n",
    "            ct_high = ct_highs[level]  # (B, 3, H, W) - [LH, HL, HH]\n",
    "            mr_high = mr_highs[level]\n",
    "            \n",
    "            # Split into subbands\n",
    "            ct_lh, ct_hl, ct_hh = ct_high[:, 0:1], ct_high[:, 1:2], ct_high[:, 2:3]\n",
    "            mr_lh, mr_hl, mr_hh = mr_high[:, 0:1], mr_high[:, 1:2], mr_high[:, 2:3]\n",
    "            \n",
    "            # Fuse each subband\n",
    "            alpha_lh = torch.sigmoid(self.fusion_params[f'high_{level}_lh'])\n",
    "            alpha_hl = torch.sigmoid(self.fusion_params[f'high_{level}_hl'])\n",
    "            alpha_hh = torch.sigmoid(self.fusion_params[f'high_{level}_hh'])\n",
    "            \n",
    "            fused_lh = alpha_lh * ct_lh + (1.0 - alpha_lh) * mr_lh\n",
    "            fused_hl = alpha_hl * ct_hl + (1.0 - alpha_hl) * mr_hl\n",
    "            fused_hh = alpha_hh * ct_hh + (1.0 - alpha_hh) * mr_hh\n",
    "            \n",
    "            # Combine subbands\n",
    "            fused_high = torch.cat([fused_lh, fused_hl, fused_hh], dim=1)\n",
    "            \n",
    "            # Apply attention and refinement\n",
    "            fused_high = self.high_attention[f'level_{level}'](fused_high)\n",
    "            if self.use_residual:\n",
    "                fused_high = self.high_refine[f'level_{level}'](fused_high)\n",
    "            \n",
    "            fused_highs.append(fused_high)\n",
    "        \n",
    "        # Inverse DWT\n",
    "        fused = self.idwt((fused_low, fused_highs))\n",
    "        \n",
    "        # Final refinement\n",
    "        refined = self.final_refine(fused)\n",
    "        \n",
    "        # Residual connection with original fusion\n",
    "        output = fused + 0.1 * refined\n",
    "        \n",
    "        return output"
   ]
  }